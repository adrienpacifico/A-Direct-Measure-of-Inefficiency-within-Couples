{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation impot concubains avec enfants biologiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-26 18:09:45\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "start_time = datetime.datetime.now(); print(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "year = 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd ; pd.set_option(\"display.max_columns\",200)\n",
    "import numpy as np\n",
    "import pickle\n",
    "import statsmodels.api as sm\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\".\\optimisation_concubains\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd ; pd.set_option(\"display.max_columns\",200)\n",
    "import numpy as np\n",
    "import pickle\n",
    "import statsmodels.api as sm\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "store_path = '../Data/hdf/edp_2015_final.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Store = pd.HDFStore(store_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_fisc_i_by_year(year = None):\n",
    "    df_fisci = pd.read_hdf(store_path, 'FISC_INDIVIDU_{}'.format(year))\n",
    "    return df_fisci\n",
    "def load_fisc_r_by_year(year = None):\n",
    "    df_fiscr = pd.read_hdf(store_path, 'FISC_REVENU_{}'.format(year))\n",
    "    return df_fiscr\n",
    "def load_fisc_l_by_year(year = None):\n",
    "    df_fiscr = pd.read_hdf(store_path, 'FISC_LOGEMENT_{}'.format(year))\n",
    "    return df_fiscr\n",
    "\n",
    "def load_df_fiscrevdet_by_year(year = None):\n",
    "    df_fiscrevdet = pd.read_hdf(store_path, 'FISC_REVDET_{}'.format(year))\n",
    "    return df_fiscrevdet\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diploma_labels = {1:\"No_school\", 2 : \"primary_middle_school\",11:\"CEP\", 12:\"BEPC\", 13:\"CAP\", 14:\"BEP\", 15:\"BAC\", 16:\"Bac_pro\",17:\"Bac_plus_3\",18:\"Master_PhD\" }\n",
    "diploma_labels_homme = {1:\"No_school_man\", 2 : \"primary_middle_school_man\",11:\"CEP_man\", 12:\"BEPC_man\", 13:\"CAP_man\", 14:\"BEP_man\", 15:\"BAC_man\", 16:\"Bac_pro_man\",17:\"Bac_plus_3_man\",18:\"Master_PhD_man\" }\n",
    "diploma_labels_femme = {1:\"No_school_wo\", 2 : \"primary_middle_school_wo\",11:\"CEP_wo\", 12:\"BEPC_wo\", 13:\"CAP_wo\", 14:\"BEP_wo\", 15:\"BAC_wo\", 16:\"Bac_pro_wo\",17:\"Bac_plus_3_wo\",18:\"Master_PhD_wo\" }\n",
    "\n",
    "\n",
    "def add_diplomas_dummies(df_temp):\n",
    "    df_temp.loc[df_temp.Diplome_femme == 3, \"Diplome_femme\"] = 2\n",
    "    df_temp.loc[df_temp.Diplome_homme == 3, \"Diplome_homme\"] = 2\n",
    "    df_temp.loc[df_temp.Diplome_femme == 19, \"Diplome_femme\"] = 18\n",
    "    df_temp.loc[df_temp.Diplome_homme == 3, \"Diplome_homme\"] = 18\n",
    "    diplome_homme = pd.get_dummies(df_temp.Diplome_homme)\n",
    "    diplome_femme = pd.get_dummies(df_temp.Diplome_femme)\n",
    "    diplome_homme = diplome_homme.rename(columns=diploma_labels_homme)\n",
    "    diplome_femme = diplome_femme.rename(columns=diploma_labels_femme)\n",
    "    df_temp = pd.concat([df_temp, diplome_homme], axis = 1)\n",
    "    df_temp = pd.concat([df_temp, diplome_femme], axis = 1)\n",
    "    \n",
    "    df_temp[\"No_education_femme\"] = df_temp.Diplome_femme.isin([1,2,11,12])\n",
    "    df_temp[\"No_education_homme\"] = df_temp.Diplome_homme.isin([1,2,11,12])\n",
    "    \n",
    "    df_temp[\"Vocational_education_femme\"] = df_temp.Diplome_femme.isin([13,14,15,16])\n",
    "    df_temp[\"Vocational_education_homme\"] = df_temp.Diplome_homme.isin([13,14,15,16])\n",
    "    \n",
    "    df_temp[\"Licence_education_femme\"] = df_temp.Diplome_femme.isin([17])\n",
    "    df_temp[\"Licence_education_homme\"] = df_temp.Diplome_homme.isin([17])\n",
    "\n",
    "    df_temp[\"Master_PhD_education_femme\"] = df_temp.Diplome_femme.isin([18])\n",
    "    df_temp[\"Master_PhD_education_homme\"] = df_temp.Diplome_homme.isin([18])\n",
    "    \n",
    "    \n",
    "    \n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdf_path = (\"./Generated_hdf/optimizers.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "biologic_path = (u\"./Pickle/biologic/biologic_households{}.p\".format(2013))\n",
    "biologic_2013 = pickle.load( \n",
    "        open(biologic_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "biologic_path = (u\"./Pickle/biologic/biologic_households{}.p\".format(2014))\n",
    "biologic_2014 = pickle.load( \n",
    "        open(biologic_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_hdf(hdf_path,  \"optimizers_{}\".format(year)).reset_index()\n",
    "df_2013 = df[df.ID_FISC_LOG_DIFF.isin(biologic_2013)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_homme_femme_ear= pd.read_hdf(\n",
    "    \"./Generated_hdf/FSCI_EAR_BIO.h5\",  \n",
    "    \"ear_groupby_id_fisc_log_diff_homme_femme\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_hdf(hdf_path,  \"optimizers_{}\".format(2014)).reset_index()\n",
    "df_2014 = df[df.ID_FISC_LOG_DIFF.isin(biologic_2014)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'pandas.io.pytables.HDFStore'>\n",
       "File path: ./Generated_hdf/optimizers.h5\n",
       "/optimizers_2013                                              frame        (shape->[173411,120])\n",
       "/optimizers_2014                                              frame        (shape->[175339,107])\n",
       "/optimizers_counterfactual_income_2013_on_tax_2014            frame        (shape->[175339,14]) \n",
       "/optimizers_counterfactual_income_2014_on_tax_2013            frame        (shape->[173411,14]) "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.HDFStore(hdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_counterfactual_1 = pd.read_hdf(hdf_path,\"optimizers_counterfactual_income_2013_on_tax_2014\"  )\n",
    "df_counterfactual_2 = pd.read_hdf(hdf_path,\"optimizers_counterfactual_income_2014_on_tax_2013\"  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_counterfactual = pd.merge(df_counterfactual_1.reset_index(), df_counterfactual_2.reset_index(),\n",
    "                             on = \"ID_FISC_LOG_DIFF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_counterfactual.drop_duplicates(subset = \"ID_FISC_LOG_DIFF\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122291"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_counterfactual.ID_FISC_LOG_DIFF.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52328, 122)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2013.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2013 = pd.merge(df_2013, df_counterfactual, on = \"ID_FISC_LOG_DIFF\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52328, 150)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2013.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pour créer le groupe ayant une unique allocation optimale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 43.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IMPTEMP_A_PACIFIC\\Desktop\\WinPython-64bit-2.7.10.2\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\IPython\\kernel\\__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "i = 0\n",
    "two_smallest_difference = np.array([])\n",
    "for df_temp in [df_2013,df_2014]:\n",
    "    for series in df_temp[[\"Irpp_decote_allocation_{}\".format(alloc_nb) for alloc_nb in range(1,9)]].iterrows():\n",
    "        two_smallest_allocations =  series[1].nsmallest(2)\n",
    "        i+=1\n",
    "        two_smallest_difference = np.append(two_smallest_difference,  two_smallest_allocations[0] - two_smallest_allocations[1]) \n",
    "    df_temp[\"Two_smallest_allocation_difference\"] = -pd.Series(two_smallest_difference)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On merge avec les infos des EAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2013_save = df_2013\n",
    "df_2014_save = df_2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2013 = df_2013_save\n",
    "df_2014 = df_2014_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_2013 = pd.merge(df_2013, df_homme_femme_ear, on= \"ID_FISC_LOG_DIFF\", how = 'left')\n",
    "df_2014 = pd.merge(df_2014, df_homme_femme_ear, on= \"ID_FISC_LOG_DIFF\", how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add change in matrimonial status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = (u\"./Pickle/optimize/\")\n",
    "mariage_id_2013_2014 = pickle.load(open(path+\"marriage_en_2013_2014.p\", 'rb'))\n",
    "pacs_id_2013_2014 = pickle.load(open(path+\"pacs_en_2013_2014.p\", 'rb'))\n",
    "separation_id_2013_2014 = pickle.load(open(path+\"separation_en_2013_2014.p\", 'rb'))\n",
    "\n",
    "\n",
    "\n",
    "df_2013['Mariage'] = df_2013.ID_FISC_LOG_DIFF.isin(mariage_id_2013_2014)\n",
    "df_2013['Pacs'] = df_2013.ID_FISC_LOG_DIFF.isin(pacs_id_2013_2014)\n",
    "df_2013['Separation'] = df_2013.ID_FISC_LOG_DIFF.isin(separation_id_2013_2014)\n",
    "df_2013[\"Mar_Pacs\"] = df_2013['Mariage'] | df_2013['Pacs']\n",
    "df_2013['Do_not_optimize_olivier'] = (df_2013.Fiscal_loss/df_2013.Rni)>0.05\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 39.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for df_temp in [df_2013, df_2014]:\n",
    "    i = 0\n",
    "    two_smallest_difference = np.array([])\n",
    "    for series in df_temp[[\"Irpp_decote_allocation_{}\".format(alloc_nb) for alloc_nb in range(1,9)]].iterrows():\n",
    "        two_smallest_allocations =  series[1].nsmallest(2)\n",
    "        i+=1\n",
    "        two_smallest_difference = np.append(two_smallest_difference,  two_smallest_allocations[0] - two_smallest_allocations[1]) \n",
    "    df_temp[\"Two_smallest_allocation_difference\"] = two_smallest_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2013[\"No_decote\"] = (df_2013.Irpp_decote==df_2013.Irpp_ac_plaf_qf)\n",
    "df_2014[\"No_decote\"] = (df_2014.Irpp_decote==df_2014.Irpp_ac_plaf_qf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "for df_temp in [df_2013, df_2014]:\n",
    "    df_temp[\"deux_enfants\"] = df_temp.Nb_enfants == 2\n",
    "    df_temp[\"trois_enfants_et_plus\"] = df_temp.Nb_enfants >= 3 \n",
    "    df_temp[\"trois_enfants\"] = df_temp.Nb_enfants == 3\n",
    "    df_temp[\"quatre_enfants_et_plus\"] = df_temp.Nb_enfants >= 4 \n",
    "    df_temp[\"Age_moyen\"] = (df_temp.Age_mere + df_temp.Age_pere)/2\n",
    "    df_temp[\"Age_moyen_parents\"] = (df_temp.Age_mere + df_temp.Age_pere)/2\n",
    "    df_temp[\"Age_moyen_squared\"] = df_temp.Age_moyen**2\n",
    "    df_temp[\"Ecart_Age_en_valeur_absolue\"] = np.abs(df_temp.Age_pere - df_temp.Age_mere)\n",
    "    df_temp[\"Prct_rev_perte_fiscale\"] = df_temp.Fiscal_loss/df_temp.Rni\n",
    "    df_temp[\"Diff_in_incompe_mere_pere\"] = np.abs(df_temp.Rni_pere - df_temp.Rni_mere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52336, 187)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2013.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age enfants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_fisci = load_fisc_i_by_year(2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_fisci_select = df_fisci[df_fisci.TYPE_FISC.isin([\"A\", \"B\", \"C\",\"D\", \"E\", \"F\",\"G\", \"H\", \"I\"])] #Garde que les enfants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_fisci_select = df_fisci_select.sort([\"ID_FISC_LOG_DIFF\", \"ANAIS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grpby = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grpby[\"Age_elder_child\"] = 2013- df_fisci_select[[\"ID_FISC_LOG_DIFF\", \"ANAIS\"]].groupby(\"ID_FISC_LOG_DIFF\").ANAIS.first()\n",
    "grpby[\"Age_younger_child\"] = 2013 - df_fisci_select[[\"ID_FISC_LOG_DIFF\", \"ANAIS\"]].groupby(\"ID_FISC_LOG_DIFF\").ANAIS.last()\n",
    "grpby[\"Age_moyen_children\"] = 2013 - df_fisci_select[[\"ID_FISC_LOG_DIFF\", \"ANAIS\"]].groupby(\"ID_FISC_LOG_DIFF\").ANAIS.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#grpby.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2013 = pd.merge(df_2013, grpby.reset_index(), on = \"ID_FISC_LOG_DIFF\", how = \"left\")\n",
    "df_2014 = pd.merge(df_2014, grpby.reset_index(), on = \"ID_FISC_LOG_DIFF\", how = \"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52336, 190)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2013.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_2013[\"Annee\"] = 2013\n",
    "df_2013[\"year_2013\"] =(df_2013.Annee == 2013)\n",
    "df_2014[\"Annee\"] = 2014\n",
    "df_2014[\"year_2014\"] =(df_2014.Annee == 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_2013.ID_FISC_LOG_DIFF;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add diplomas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_2013 = add_diplomas_dummies(df_2013)\n",
    "df_2014 = add_diplomas_dummies(df_2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diploma_4_categories = [\"No_education_femme\", \"Vocational_education_femme\",\"Licence_education_femme\", \"Master_PhD_education_femme\",\n",
    "                       \"No_education_homme\", \"Vocational_education_homme\",\"Licence_education_homme\", \"Master_PhD_education_homme\"]\n",
    "diploma_4_categories_to_regress =  [\"Vocational_education_femme\",\"Licence_education_femme\", \"Master_PhD_education_femme\",\n",
    "                       \"Vocational_education_homme\",\"Licence_education_homme\", \"Master_PhD_education_homme\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IMPTEMP_A_PACIFIC\\Desktop\\WinPython-64bit-2.7.10.2\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\pandas\\computation\\expressions.py:190: UserWarning: evaluating in Python space because the '*' operator is not supported by numexpr for the bool dtype, use '&' instead\n",
      "  unsupported[op_str]))\n",
      "C:\\Users\\IMPTEMP_A_PACIFIC\\Desktop\\WinPython-64bit-2.7.10.2\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\pandas\\computation\\expressions.py:190: UserWarning: evaluating in Python space because the '+' operator is not supported by numexpr for the bool dtype, use '|' instead\n",
      "  unsupported[op_str]))\n"
     ]
    }
   ],
   "source": [
    "for df_temp in [df_2013, df_2014]:\n",
    "    df_temp[\"Same_diploma\"] = (df_temp[\"No_education_femme\"]*df_temp[\"No_education_homme\"]+\n",
    "                            df_temp[\"Vocational_education_femme\"]*df_temp[\"Vocational_education_homme\"]+\n",
    "                            df_temp[\"Licence_education_femme\"]*df_temp[\"Licence_education_homme\"]+\n",
    "                            df_temp[\"Master_PhD_education_femme\"]*df_temp[\"Master_PhD_education_homme\"])\n",
    "\n",
    "\n",
    "    df_temp[\"Same_diploma_No_educ\"] = (df_temp[\"No_education_femme\"]*df_temp[\"No_education_homme\"])\n",
    "    df_temp[\"Same_diploma_Vocational\"] = (df_temp[\"Vocational_education_femme\"]*df_temp[\"Vocational_education_homme\"])\n",
    "    df_temp[\"Same_diploma_licence\"] =  (df_temp[\"Licence_education_femme\"]*df_temp[\"Licence_education_homme\"])\n",
    "    df_temp[\"Same_diploma_Master\"] = (df_temp[\"Master_PhD_education_femme\"]*df_temp[\"Master_PhD_education_homme\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52336, 226)\n",
      "(33044, 226)\n"
     ]
    }
   ],
   "source": [
    "print df_2013.shape\n",
    "print df_2013[df_2013[diploma_4_categories].sum(axis = 1) == 2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var_revenus_fiscr = ['ZTSAM',\n",
    "       u'ZSALM', u'ZCHOM', u'ZPERM', u'ZRETM', u'ZRSTM', u'ZALRM', u'ZRTOM',\n",
    "       u'ZRAGM', u'ZRICM', u'ZRNCM', u'ZFONM', u'ZVAMM0', u'ZVAMM', u'ZVALM0',\n",
    "       u'ZVALM', u'ZRACM', u'ZETRM', u'ZALVM']\n",
    "\n",
    "var_revenus_fiscrevdet = ['YSALI','YCHOI','YRAGI','YBICI','YBNCI','YRSTI','YALRI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_2013_can_optimize = df_2013[(df_2013.result_min_allocation < df_2013.result_max_allocation )]\n",
    "df_2014_can_optimize = df_2014[(df_2014.result_min_allocation < df_2014.result_max_allocation )]\n",
    "df_no_decote_2013 = df_2013[(df_2013.Irpp_decote==df_2013.Irpp_ac_plaf_qf)]\n",
    "df_no_decote_2014 = df_2014[(df_2014.Irpp_decote==df_2014.Irpp_ac_plaf_qf)]\n",
    "df_no_decote_can_optimize_2013 = df_2013[(df_2013.Irpp_decote==df_2013.Irpp_ac_plaf_qf) &  (df_2013.result_min_allocation < df_2013.result_max_allocation )]\n",
    "df_no_decote_can_optimize_2014 = df_2014[(df_2014.Irpp_decote==df_2014.Irpp_ac_plaf_qf)& (df_2014.result_min_allocation < df_2014.result_max_allocation )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2013_A = df_2013\n",
    "df2013_B = df_2013_can_optimize\n",
    "df2013_C = df_no_decote_can_optimize_2013\n",
    "df2013_D = df2013_B[df2013_B.Two_smallest_allocation_difference<0]\n",
    "df2014_A = df_2014\n",
    "df2014_B = df_2014_can_optimize\n",
    "df2014_C = df_no_decote_can_optimize_2014\n",
    "df2014_D = df2014_B[df2014_B.Two_smallest_allocation_difference<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((24548, 226), (24548, 226))\n"
     ]
    }
   ],
   "source": [
    "print(df2013_B.query(\"Nb_enfants == 1\").shape,df2013_D.query(\"Nb_enfants == 1\").shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Test that for 1 child families the number of \"can optimize household\" is the same as \"unique optimal allocation\"\n",
    "assert (df2013_B.query(\"Nb_enfants == 1\").shape == df2013_D.query(\"Nb_enfants == 1\").shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_A = pd.merge(df2013_A, df2014_A, on=\"ID_FISC_LOG_DIFF\", suffixes = (\"_2013\", \"_2014\"))\n",
    "df_B = pd.merge(df2013_B, df2014_B, on=\"ID_FISC_LOG_DIFF\", suffixes = (\"_2013\", \"_2014\"))\n",
    "df_C = pd.merge(df2013_C, df2014_C, on=\"ID_FISC_LOG_DIFF\", suffixes = (\"_2013\", \"_2014\"))\n",
    "df_D = pd.merge(df2013_D, df2014_D, on=\"ID_FISC_LOG_DIFF\", suffixes = (\"_2013\", \"_2014\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32272, 405)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "irrp_decote_allocation_var_name = [\"Irpp_decote_allocation_{}_2013\".format(nb_alloc) for nb_alloc in range(1,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  For group A\n",
      "\n",
      "  For group C\n",
      "\n",
      "  For group B\n"
     ]
    }
   ],
   "source": [
    "for df_group_name, df_temp in {\"A\":df_A,\"B\":df_B,\"C\":df_C}.iteritems():\n",
    "    print \"\\n  For group\", df_group_name\n",
    "    df_temp[\"optimiseurs_2013_2014\"]=(~df_temp.Do_not_optimize_2013 & ~df_temp.Do_not_optimize_2014)\n",
    "    df_temp[\"non_opt_2013_opt_2014\"]=(df_temp.Do_not_optimize_2013 & ~df_temp.Do_not_optimize_2014)\n",
    "    df_temp[\"opt_2013_non_opt_2014\"]=(~df_temp.Do_not_optimize_2013 & df_temp.Do_not_optimize_2014)\n",
    "    df_temp[\"non_opt_2013_2014\"]=(df_temp.Do_not_optimize_2013 & df_temp.Do_not_optimize_2014)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same optimal allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for sub_group in [\"optimiseurs_2013_2014\",\"non_opt_2013_opt_2014\",\"opt_2013_non_opt_2014\",\"non_opt_2013_2014\"]:\n",
    "    #print sub_group\n",
    "    for df_group_name, df_temp in {\"A\":df_A.query(\"{}\".format(sub_group)),\n",
    "                                   \"B\":df_B.query(\"{}\".format(sub_group)),\n",
    "                                   \"C\":df_C.query(\"{}\".format(sub_group))}.iteritems():\n",
    "        #print \"For group\", df_group_name, \", sample size = \", df_temp.shape[0]\n",
    "        melt_2013 = pd.melt(df_temp[[\"ID_FISC_LOG_DIFF\"]+ [\"Irpp_decote_allocation_{}_2013\".format(nb_alloc) for nb_alloc in range(1,10)]]\n",
    "                    , id_vars = \"ID_FISC_LOG_DIFF\")\n",
    "        idx_2013 = melt_2013.groupby(\"ID_FISC_LOG_DIFF\").value.transform(min) == melt_2013.value\n",
    "        melt_2014 = pd.melt(df_temp[[\"ID_FISC_LOG_DIFF\"]+ [\"Irpp_decote_allocation_{}_2014\".format(nb_alloc) for nb_alloc in range(1,10)]]\n",
    "                    , id_vars = \"ID_FISC_LOG_DIFF\")\n",
    "        idx_2014 = melt_2014.groupby(\"ID_FISC_LOG_DIFF\").value.transform(min) == melt_2014.value\n",
    "        variable_2014 = melt_2014[idx_2014].sort(\"ID_FISC_LOG_DIFF\")[[\"ID_FISC_LOG_DIFF\",\"variable\"]]\n",
    "        variable_2013 = melt_2013[idx_2013].sort(\"ID_FISC_LOG_DIFF\")[[\"ID_FISC_LOG_DIFF\",\"variable\"]]\n",
    "        df_temp = pd.merge(variable_2014, df_temp, on=\"ID_FISC_LOG_DIFF\")\n",
    "        df_temp = pd.merge(variable_2013, df_temp, on=\"ID_FISC_LOG_DIFF\", suffixes = (\"_2013\", \"_2014\"))\n",
    "        df_temp[\"Same_optimal_allocation\"] = (df_temp.variable_2013.str[:-5] == df_temp.variable_2014.str[:-5]).astype('bool')\n",
    "        #print df_temp.query(\"Nb_enfants_2013 == Nb_enfants_2014 \").groupby(\"ID_FISC_LOG_DIFF\").Same_optimal_allocation.sum().value_counts()\n",
    "        df_temp.query(\"Nb_enfants_2013 == Nb_enfants_2014 \").groupby(\"ID_FISC_LOG_DIFF\").Same_optimal_allocation.sum().astype(\"bool\").value_counts(normalize = True)[False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Same optimal allocation (same number of children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For group A , sample size =  38249\n",
      "0.144881290436\n",
      "For group C , sample size =  4838\n",
      "0.117737338303\n",
      "For group B , sample size =  32272\n",
      "0.170708150805\n",
      "For group D , sample size =  27656\n",
      "0.189263646739\n"
     ]
    }
   ],
   "source": [
    "for df_group_name, df_temp in { \"A\":df_A, \"B\":df_B,\"C\":df_C, \"D\":df_D}.iteritems():\n",
    "    df_temp.reset_index(inplace=True)\n",
    "    print \"For group\", df_group_name, \", sample size = \", df_temp.shape[0]\n",
    "    melt_2013 = pd.melt(df_temp[[\"ID_FISC_LOG_DIFF\"]+ [\"Irpp_decote_allocation_{}_2013\".format(nb_alloc) for nb_alloc in range(1,10)]]\n",
    "                , id_vars = \"ID_FISC_LOG_DIFF\")\n",
    "    idx_2013 = melt_2013.groupby(\"ID_FISC_LOG_DIFF\").value.transform(min) == melt_2013.value\n",
    "    melt_2014 = pd.melt(df_temp[[\"ID_FISC_LOG_DIFF\"]+ [\"Irpp_decote_allocation_{}_2014\".format(nb_alloc) for nb_alloc in range(1,10)]]\n",
    "                , id_vars = \"ID_FISC_LOG_DIFF\")\n",
    "    idx_2014 = melt_2014.groupby(\"ID_FISC_LOG_DIFF\").value.transform(min) == melt_2014.value\n",
    "    variable_2014 = melt_2014[idx_2014].sort(\"ID_FISC_LOG_DIFF\")[[\"ID_FISC_LOG_DIFF\",\"variable\"]]\n",
    "    variable_2013 = melt_2013[idx_2013].sort(\"ID_FISC_LOG_DIFF\")[[\"ID_FISC_LOG_DIFF\",\"variable\"]]\n",
    "    df_temp_2 = pd.merge(variable_2014, df_temp, on=\"ID_FISC_LOG_DIFF\")\n",
    "    df_temp_2 = pd.merge(variable_2013, df_temp_2, on=\"ID_FISC_LOG_DIFF\", suffixes = (\"_2013\", \"_2014\"))\n",
    "    df_temp_2[\"Same_optimal_allocation\"] = (df_temp_2.variable_2013.str[:-5] == df_temp_2.variable_2014.str[:-5]).astype('bool')\n",
    "    #print df_temp.query(\"Nb_enfants_2013 == Nb_enfants_2014 \").groupby(\"ID_FISC_LOG_DIFF\").Same_optimal_allocation.sum().value_counts()\n",
    "    print df_temp_2.query(\"Nb_enfants_2013 == Nb_enfants_2014 \").groupby(\"ID_FISC_LOG_DIFF\").Same_optimal_allocation.sum(\n",
    "                    ).astype(\"bool\").value_counts(normalize = True)[False]\n",
    "    ##Warning!!! attention fait à l'arrache, on est censé avoir autent d'obs dans df_temp que dans df_temp_2, chercher d'ou viennent les drop\n",
    "    df_temp.set_index(\"ID_FISC_LOG_DIFF\", inplace = True)\n",
    "    df_temp[\"Same_optimal_allocation_same_family\"] =  df_temp_2.query(\"Nb_enfants_2013 == Nb_enfants_2014 \").groupby(\"ID_FISC_LOG_DIFF\").Same_optimal_allocation.sum()\n",
    "    df_temp.Same_optimal_allocation_same_family.fillna(0, inplace = True) ; df_temp.reset_index(\"ID_FISC_LOG_DIFF\", inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "C\n",
      "B\n",
      "D\n"
     ]
    }
   ],
   "source": [
    "for df_group_name, df_temp in {\"A\":df_A,\"B\":df_B,\"C\":df_C, \"D\":df_D}.iteritems():\n",
    "    print df_group_name\n",
    "    ##\n",
    "    ## Rajouté après allocations optimales (flemme de bien nettoyer plus haut)\n",
    "    ##\n",
    "    \n",
    "    melt_2013 = pd.melt(df_temp[[\"ID_FISC_LOG_DIFF\"]+ [\"Irpp_decote_allocation_{}_2013\".format(nb_alloc) for nb_alloc in range(1,10)]]\n",
    "                , id_vars = \"ID_FISC_LOG_DIFF\")\n",
    "    idx_2013 = melt_2013.groupby(\"ID_FISC_LOG_DIFF\").value.transform(min) == melt_2013.value\n",
    "    melt_2014 = pd.melt(df_temp[[\"ID_FISC_LOG_DIFF\"]+ [\"Irpp_decote_allocation_{}_2014\".format(nb_alloc) for nb_alloc in range(1,10)]]\n",
    "                , id_vars = \"ID_FISC_LOG_DIFF\")\n",
    "    idx_2014 = melt_2014.groupby(\"ID_FISC_LOG_DIFF\").value.transform(min) == melt_2014.value\n",
    "    variable_2014 = melt_2014[idx_2014].sort(\"ID_FISC_LOG_DIFF\")[[\"ID_FISC_LOG_DIFF\",\"variable\"]]\n",
    "    variable_2013 = melt_2013[idx_2013].sort(\"ID_FISC_LOG_DIFF\")[[\"ID_FISC_LOG_DIFF\",\"variable\"]]\n",
    "    \n",
    "    \n",
    "    \n",
    "    variable_2013[\"Allocations_optimales_2013\"] = variable_2013.sort(\"ID_FISC_LOG_DIFF\").variable.str[12:24]\n",
    "    variable_2014[\"Allocations_optimales_2014\"] = variable_2014.sort(\"ID_FISC_LOG_DIFF\").variable.str[12:24]\n",
    "    #df_temp[\"Test_allocaton_optimale\"] = variable_2013.groupby(\"ID_FISC_LOG_DIFF\", as_index = True).sum()[Allocations_optimales_2013]\n",
    "    df_temp.set_index('ID_FISC_LOG_DIFF', inplace = True)\n",
    "    df_temp[\"Optimal_allocations_2013\"] = variable_2013.groupby(\"ID_FISC_LOG_DIFF\", as_index = True).sum()[\"Allocations_optimales_2013\"] #TODO mettre ça dans préparation générale\n",
    "    df_temp[\"Optimal_allocations_2014\"] = variable_2014.groupby(\"ID_FISC_LOG_DIFF\", as_index = True).sum()[\"Allocations_optimales_2014\"]\n",
    "    df_temp['Chosen_allocation_2013'] = df_temp.Nb_enfants_2013+1 - df_temp.Allocation_mere_2013\n",
    "    df_temp['Chosen_allocation_2014'] = df_temp.Nb_enfants_2014+1 - df_temp.Allocation_mere_2014\n",
    "    \n",
    "    df_temp[\"Number_of_optimal_allocations_2013\"] = df_temp.Optimal_allocations_2013.str.len()/12\n",
    "    df_temp[\"Number_of_optimal_allocations_2014\"] = df_temp.Optimal_allocations_2014.str.len()/12\n",
    "    \n",
    "    df_temp.reset_index(inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "C"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IMPTEMP_A_PACIFIC\\Desktop\\WinPython-64bit-2.7.10.2\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\IPython\\kernel\\__main__.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\IMPTEMP_A_PACIFIC\\Desktop\\WinPython-64bit-2.7.10.2\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\IPython\\kernel\\__main__.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "B\n",
      "D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IMPTEMP_A_PACIFIC\\Desktop\\WinPython-64bit-2.7.10.2\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\IPython\\kernel\\__main__.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "## Pour l'année 2013 \n",
    "for df_group_name, df_temp in {\"A\":df2013_A,\"B\":df2013_B,\"C\":df2013_C, \"D\":df2013_D}.iteritems():\n",
    "    print df_group_name\n",
    "    ##\n",
    "    ## Rajouté après allocations optimales (flemme de bien nettoyer plus haut)\n",
    "    ##\n",
    "    \n",
    "    melt_2013 = pd.melt(df_temp[[\"ID_FISC_LOG_DIFF\"]+ [\"Irpp_decote_allocation_{}\".format(nb_alloc) for nb_alloc in range(1,10)]]\n",
    "                , id_vars = \"ID_FISC_LOG_DIFF\")\n",
    "    idx_2013 = melt_2013.groupby(\"ID_FISC_LOG_DIFF\").value.transform(min) == melt_2013.value\n",
    "    variable_2013 = melt_2013[idx_2013].sort(\"ID_FISC_LOG_DIFF\")[[\"ID_FISC_LOG_DIFF\",\"variable\"]]\n",
    "    \n",
    "    \n",
    "    \n",
    "    variable_2013[\"Allocations_optimales\"] = variable_2013.sort(\"ID_FISC_LOG_DIFF\").variable.str[12:24]\n",
    "    #df_temp[\"Test_allocaton_optimale\"] = variable_2013.groupby(\"ID_FISC_LOG_DIFF\", as_index = True).sum()[Allocations_optimales_2013]\n",
    "    df_temp.set_index('ID_FISC_LOG_DIFF', inplace = True)\n",
    "    df_temp[\"Optimal_allocations\"] = variable_2013.groupby(\"ID_FISC_LOG_DIFF\", as_index = True).sum()[\"Allocations_optimales\"] #TODO mettre ça dans préparation générale\n",
    "    df_temp['Chosen_allocation'] = df_temp.Nb_enfants+1 - df_temp.Allocation_mere\n",
    "    \n",
    "    df_temp[\"Number_of_optimal_allocations\"] = df_temp.Optimal_allocations.str.len()/12\n",
    "    \n",
    "    df_temp.reset_index(inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# melt_2013 = pd.melt(df_temp[[\"ID_FISC_LOG_DIFF\"]+ [\"Irpp_decote_allocation_{}_2013\".format(nb_alloc) for nb_alloc in range(1,10)]]\n",
    "#                 , id_vars = \"ID_FISC_LOG_DIFF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "melt_2014[\"min_alloc\"] = melt_2014.groupby(\"ID_FISC_LOG_DIFF\").value.transform(min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#melt_2014.sort(\"ID_FISC_LOG_DIFF\").tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "melt_2014[\"Alloc_is_optimal\"] = (melt_2014.value == melt_2014.min_alloc).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    27648\n",
       "4        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melt_2014.groupby(\"ID_FISC_LOG_DIFF\").Alloc_is_optimal.sum().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     32081\n",
       "2      3845\n",
       "3      1761\n",
       "4       342\n",
       "5       171\n",
       "6        22\n",
       "7        21\n",
       "36        4\n",
       "12        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO fonctionne plus, voir data_preparation_copy_1 pour avoir le bon output.\n",
    "(df_A.Optimal_allocations_2013.str.len()/12).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les allocations sont classées comme suit : l'allocation 1 correspond à l'allocation ou la même prend tout les enfants, et la dernière allocation correspond à l'allocation ou le père prend tout les enfants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_B[[\"Test_to_trash\",\"Chosen_allocation\", \"Allocation_mere_2013\", \"Allocation_pere_2013\", \"Do_not_optimize_2013\"]+['Irpp_decote_allocation_{}_2013'.format(aloc) for aloc in range(1,6)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for df_temp in [df_A,df_B,df_C, df_D]:\n",
    "    same_family_same_allocation = ((df_temp.Nb_enfants_2013 == df_temp.Nb_enfants_2014)&\n",
    "                              (df_temp.Allocation_mere_2013 == df_temp.Allocation_mere_2014))\n",
    "    same_family_different_allocation = ((df_temp.Nb_enfants_2013 == df_temp.Nb_enfants_2014)&\n",
    "                              (df_temp.Allocation_mere_2013 != df_temp.Allocation_mere_2014))\n",
    "    df_temp[\"Same_family_did_not_change_allocation\"] = same_family_same_allocation.astype('int')\n",
    "    df_temp[\"Same_family_did_change_allocation\"] = same_family_different_allocation.astype('int')\n",
    "    \n",
    "    \n",
    "    df_temp[\"Family_change\"] = df_temp.Nb_enfants_2013 != df_temp.Nb_enfants_2014\n",
    "    df_temp[\"Family_child_gain\"] = df_temp.Nb_enfants_2013 < df_temp.Nb_enfants_2014\n",
    "    df_temp[\"Family_child_loss\"] = df_temp.Nb_enfants_2013 > df_temp.Nb_enfants_2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_concat_A = pd.concat([df2013_A, df2014_A])\n",
    "df_concat_B = pd.concat([df2013_B, df2014_B])\n",
    "df_concat_C = pd.concat([df2013_C, df2014_C])\n",
    "df_concat_D = pd.concat([df2013_D, df2014_D])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "for df_temp in [df_concat_A, df_concat_B, df_concat_C, df_concat_D]:\n",
    "    df_temp[\"year_2013\"].fillna(False, inplace=True)\n",
    "    df_temp[\"year_2014\"].fillna(False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_concat_A.Ecart_Age_en_valeur_absolue.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32272, 422)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep households with diplomas only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diploma_4_categories_2013 = [a + \"_2013\" for a in diploma_4_categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# daframes_list = {\"df2013_A\":df2013_A,\"df2013_B\":df2013_B, \"df2013_C\":df2013_C,\"df2013_D\":df2013_D, \n",
    "#                     \"df2014_A\":df2014_A,\"df2014_B\":df2014_B, \"df2014_C\":df2014_C, \"df2014_D\":df2014_D,\n",
    "#                     \"df_concat_A\":df_concat_A, \"df_concat_B\":df_concat_B,\"df_concat_C\":df_concat_C,\"df_concat_D\":df_concat_D,\n",
    "#                     \"df_A\": df_A, \"df_B\": df_B, \"df_C\":df_C,\"df_D\":df_D,}\n",
    "# for key, df_temp in daframes_list.iteritems():\n",
    "#         print key, df_temp.shape\n",
    "#         try:\n",
    "#             df_temp = df_temp[df_temp[diploma_4_categories].sum(axis = 1) == 2]\n",
    "#             daframes_list[key] = df_temp\n",
    "#         except KeyError: #Deal with diplomas variable having the year in the end of the name\n",
    "#             try: \n",
    "#                 df_temp = df_temp[df_temp[diploma_4_categories_2013].sum(axis = 1) == 2]\n",
    "#                 daframes_list[key] = df_temp\n",
    "#             except: Boum\n",
    "                \n",
    "# for key, df_temp in daframes_list.iteritems():\n",
    "#         print key, df_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "daframes_list = {\"df2013_A\":df2013_A,\"df2013_B\":df2013_B, \"df2013_C\":df2013_C,\"df2013_D\":df2013_D, \n",
    "                    \"df2014_A\":df2014_A,\"df2014_B\":df2014_B, \"df2014_C\":df2014_C, \"df2014_D\":df2014_D,\n",
    "                    \"df_concat_A\":df_concat_A, \"df_concat_B\":df_concat_B,\"df_concat_C\":df_concat_C,\"df_concat_D\":df_concat_D,\n",
    "                    \"df_A\": df_A, \"df_B\": df_B, \"df_C\":df_C,\"df_D\":df_D,}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data for exploitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf_for_exploitation_path = (\"./Generated_hdf/data_to_exploit.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IMPTEMP_A_PACIFIC\\Desktop\\WinPython-64bit-2.7.10.2\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\pandas\\io\\pytables.py:2577: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->axis0] [items->None]\n",
      "\n",
      "  warnings.warn(ws, PerformanceWarning)\n",
      "C:\\Users\\IMPTEMP_A_PACIFIC\\Desktop\\WinPython-64bit-2.7.10.2\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\pandas\\io\\pytables.py:2577: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_items] [items->None]\n",
      "\n",
      "  warnings.warn(ws, PerformanceWarning)\n",
      "C:\\Users\\IMPTEMP_A_PACIFIC\\Desktop\\WinPython-64bit-2.7.10.2\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\pandas\\io\\pytables.py:2577: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block4_values] [items->['level_0', 'Counterfactual_2013_ir_on_2014_rni_Do_not_optimize', 'Counterfactual_2013_ir_on_2014_rni_Do_not_optimize_1_prct_income_share', 'Counterfactual_2014_ir_on_2013_rni_Do_not_optimize', 'Counterfactual_2014_ir_on_2013_rni_Do_not_optimize_1_prct_income_share', 'Categorie_sociale_homme', 'Immigre_IMMI_homme', 'Position_professionnelle_femme', 'Position_professionnelle_homme', 'Temps_partiel_femme', 'Temps_partiel_homme', 'Temps_recherche_emploi_femme', 'Temps_recherche_emploi_homme', 'Travaille_dans_commune_ILTD_femme', 'Travaille_dans_commune_ILTD_homme', 'Type_contrat_travail_EMPL_femme', 'Type_contrat_travail_EMPL_homme', 'Optimal_allocations']]\n",
      "\n",
      "  warnings.warn(ws, PerformanceWarning)\n",
      "C:\\Users\\IMPTEMP_A_PACIFIC\\Desktop\\WinPython-64bit-2.7.10.2\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\pandas\\io\\pytables.py:2577: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block4_values] [items->['Categorie_sociale_homme', 'Counterfactual_2013_ir_on_2014_rni_Do_not_optimize', 'Counterfactual_2013_ir_on_2014_rni_Do_not_optimize_1_prct_income_share', 'Counterfactual_2014_ir_on_2013_rni_Do_not_optimize', 'Counterfactual_2014_ir_on_2013_rni_Do_not_optimize_1_prct_income_share', 'Do_not_optimize_olivier', 'Gain_fiscal_au_pacs', 'Immigre_IMMI_homme', 'Mar_Pacs', 'Mariage', 'Neutre_au_pacs', 'Optimal_allocations', 'Pacs', 'Perte_fiscale_au_pacs', 'Plafond_qf', 'Position_professionnelle_femme', 'Position_professionnelle_homme', 'Separation', 'Temps_partiel_femme', 'Temps_partiel_homme', 'Temps_recherche_emploi_femme', 'Temps_recherche_emploi_homme', 'Travaille_dans_commune_ILTD_femme', 'Travaille_dans_commune_ILTD_homme', 'Type_contrat_travail_EMPL_femme', 'Type_contrat_travail_EMPL_homme', 'level_0']]\n",
      "\n",
      "  warnings.warn(ws, PerformanceWarning)\n",
      "C:\\Users\\IMPTEMP_A_PACIFIC\\Desktop\\WinPython-64bit-2.7.10.2\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\pandas\\io\\pytables.py:2577: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block4_values] [items->['level_0_2013', 'Counterfactual_2013_ir_on_2014_rni_Do_not_optimize', 'Counterfactual_2013_ir_on_2014_rni_Do_not_optimize_1_prct_income_share', 'Counterfactual_2014_ir_on_2013_rni_Do_not_optimize', 'Counterfactual_2014_ir_on_2013_rni_Do_not_optimize_1_prct_income_share', 'Categorie_sociale_homme_2013', 'Immigre_IMMI_homme_2013', 'Position_professionnelle_femme_2013', 'Position_professionnelle_homme_2013', 'Temps_partiel_femme_2013', 'Temps_partiel_homme_2013', 'Temps_recherche_emploi_femme_2013', 'Temps_recherche_emploi_homme_2013', 'Travaille_dans_commune_ILTD_femme_2013', 'Travaille_dans_commune_ILTD_homme_2013', 'Type_contrat_travail_EMPL_femme_2013', 'Type_contrat_travail_EMPL_homme_2013', 'level_0_2014', 'Categorie_sociale_homme_2014', 'Immigre_IMMI_homme_2014', 'Position_professionnelle_femme_2014', 'Position_professionnelle_homme_2014', 'Temps_partiel_femme_2014', 'Temps_partiel_homme_2014', 'Temps_recherche_emploi_femme_2014', 'Temps_recherche_emploi_homme_2014', 'Travaille_dans_commune_ILTD_femme_2014', 'Travaille_dans_commune_ILTD_homme_2014', 'Type_contrat_travail_EMPL_femme_2014', 'Type_contrat_travail_EMPL_homme_2014', 'Optimal_allocations_2013', 'Optimal_allocations_2014']]\n",
      "\n",
      "  warnings.warn(ws, PerformanceWarning)\n",
      "C:\\Users\\IMPTEMP_A_PACIFIC\\Desktop\\WinPython-64bit-2.7.10.2\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\pandas\\io\\pytables.py:2577: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block4_values] [items->['level_0', 'Categorie_sociale_homme', 'Immigre_IMMI_homme', 'Position_professionnelle_femme', 'Position_professionnelle_homme', 'Temps_partiel_femme', 'Temps_partiel_homme', 'Temps_recherche_emploi_femme', 'Temps_recherche_emploi_homme', 'Travaille_dans_commune_ILTD_femme', 'Travaille_dans_commune_ILTD_homme', 'Type_contrat_travail_EMPL_femme', 'Type_contrat_travail_EMPL_homme']]\n",
      "\n",
      "  warnings.warn(ws, PerformanceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for key, df_temp in daframes_list.iteritems():\n",
    "    df_temp.to_hdf(hdf_for_exploitation_path, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'pandas.io.pytables.HDFStore'>\n",
       "File path: ./Generated_hdf/data_to_exploit.h5\n",
       "/df2013_A               frame        (shape->[52336,81]) \n",
       "/df2013_B               frame        (shape->[46446,81]) \n",
       "/df2013_C               frame        (shape->[9049,81])  \n",
       "/df2013_D               frame        (shape->[43418,81]) \n",
       "/df2014_A               frame        (shape->[54313,67]) \n",
       "/df2014_B               frame        (shape->[45873,67]) \n",
       "/df2014_C               frame        (shape->[13403,67]) \n",
       "/df2014_D               frame        (shape->[39853,67]) \n",
       "/df_A                   frame        (shape->[38249,422])\n",
       "/df_B                   frame        (shape->[32272,422])\n",
       "/df_C                   frame        (shape->[4838,422]) \n",
       "/df_D                   frame        (shape->[27656,418])\n",
       "/df_concat_A            frame        (shape->[106649,82])\n",
       "/df_concat_B            frame        (shape->[92319,82]) \n",
       "/df_concat_C            frame        (shape->[22452,82]) \n",
       "/df_concat_D            frame        (shape->[83271,82]) "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.HDFStore(hdf_for_exploitation_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('now: ', datetime.datetime(2019, 4, 26, 18, 12, 45, 341000))\n",
      "('execution_time: ', datetime.timedelta(0, 180, 341000))\n"
     ]
    }
   ],
   "source": [
    "stop_time = datetime.datetime.now(); print(\"now: \",stop_time);\n",
    "execution_time = stop_time - start_time; print(\"execution_time: \",execution_time)\n",
    "stop_time = start_time\n",
    "#clear  memory\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
