{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'C:\\\\Users\\\\IMPTEMP_A_PACIFIC\\\\Desktop\\\\Cohabitant_project(EDP_2015)\\\\Programme\\\\biologic_script'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_fisci = load_fisc_i_by_year(year = income_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot convert NA to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-414546a33ca5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_fisci\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID_DIFF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"int\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\IMPTEMP_A_PACIFIC\\Desktop\\WinPython-64bit-2.7.10.2\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, raise_on_error, **kwargs)\u001b[0m\n\u001b[0;32m   2409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2410\u001b[0m         mgr = self._data.astype(\n\u001b[1;32m-> 2411\u001b[1;33m             dtype=dtype, copy=copy, raise_on_error=raise_on_error, **kwargs)\n\u001b[0m\u001b[0;32m   2412\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmgr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\IMPTEMP_A_PACIFIC\\Desktop\\WinPython-64bit-2.7.10.2\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[0;32m   2502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2503\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2504\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'astype'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2505\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2506\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\IMPTEMP_A_PACIFIC\\Desktop\\WinPython-64bit-2.7.10.2\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, axes, filter, do_integrity_check, **kwargs)\u001b[0m\n\u001b[0;32m   2457\u001b[0m                                                  copy=align_copy)\n\u001b[0;32m   2458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2459\u001b[1;33m             \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2461\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\IMPTEMP_A_PACIFIC\\Desktop\\WinPython-64bit-2.7.10.2\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, raise_on_error, values, **kwargs)\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_on_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m         return self._astype(dtype, copy=copy, raise_on_error=raise_on_error,\n\u001b[1;32m--> 373\u001b[1;33m                             values=values, **kwargs)\n\u001b[0m\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m     def _astype(self, dtype, copy=False, raise_on_error=True, values=None,\n",
      "\u001b[1;32mC:\\Users\\IMPTEMP_A_PACIFIC\\Desktop\\WinPython-64bit-2.7.10.2\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36m_astype\u001b[1;34m(self, dtype, copy, raise_on_error, values, klass, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m                 \u001b[1;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_astype_nansafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m             newb = make_block(values,\n",
      "\u001b[1;32mC:\\Users\\IMPTEMP_A_PACIFIC\\Desktop\\WinPython-64bit-2.7.10.2\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\pandas\\core\\common.pyc\u001b[0m in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy)\u001b[0m\n\u001b[0;32m   2726\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2727\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2728\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cannot convert NA to integer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2729\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobject_\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2730\u001b[0m         \u001b[1;31m# work around NumPy brokenness, #1987\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot convert NA to integer"
     ]
    }
   ],
   "source": [
    "df_fisci.ID_DIFF.astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7897225, 28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_DIFF</th>\n",
       "      <th>ID_EVT_DIFF</th>\n",
       "      <th>EVT_TYPE</th>\n",
       "      <th>OPE_TYPE</th>\n",
       "      <th>ENF_IND_SEXE</th>\n",
       "      <th>ENF_IND_NAI_DATE</th>\n",
       "      <th>ENF_IND_NAI_LIEU_DEPCOM</th>\n",
       "      <th>PERE_IND_NAI_DATE</th>\n",
       "      <th>MERE_IND_NAI_DATE</th>\n",
       "      <th>PERE_IND_NAI_LIEU_DEPCOM</th>\n",
       "      <th>MERE_IND_NAI_LIEU_DEPCOM</th>\n",
       "      <th>PERE_ADR_LIEU_DEPCOM</th>\n",
       "      <th>MERE_ADR_LIEU_DEPCOM</th>\n",
       "      <th>ADRDOMPAR</th>\n",
       "      <th>PERE_NAT_CODE</th>\n",
       "      <th>MERE_NAT_CODE</th>\n",
       "      <th>PERE_CS_CODE</th>\n",
       "      <th>MERE_CS_CODE</th>\n",
       "      <th>MAR_DATE</th>\n",
       "      <th>MAR_LIEU_DEPCOM</th>\n",
       "      <th>ORIGINOM</th>\n",
       "      <th>ENF_GEMEL_INDIC</th>\n",
       "      <th>CTX_MERE_VIVANT_ENF_PREC_NBR</th>\n",
       "      <th>CTX_NAV_PREC_DATE</th>\n",
       "      <th>NB_EDP</th>\n",
       "      <th>CTX_CATACC</th>\n",
       "      <th>CTX_ACC_ENF_NBR</th>\n",
       "      <th>I_ENF_IND_NAI_DATE</th>\n",
       "      <th>I_ENF_IND_SEXE</th>\n",
       "      <th>I_MAR_DATE</th>\n",
       "      <th>I_MAR_LIEU_DEPCOM</th>\n",
       "      <th>I_MERE_ADR_LIEU_DEPCOM</th>\n",
       "      <th>I_MERE_IND_NAI_DATE</th>\n",
       "      <th>I_MERE_IND_NAI_LIEU_DEPCOM</th>\n",
       "      <th>I_MERE_NAT_CODE</th>\n",
       "      <th>I_MERE_CS_CODE</th>\n",
       "      <th>I_PERE_ADR_LIEU_DEPCOM</th>\n",
       "      <th>I_PERE_IND_NAI_DATE</th>\n",
       "      <th>I_PERE_IND_NAI_LIEU_DEPCOM</th>\n",
       "      <th>I_PERE_NAT_CODE</th>\n",
       "      <th>I_PERE_CS_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000079705</td>\n",
       "      <td>727</td>\n",
       "      <td>JAP</td>\n",
       "      <td>PERE</td>\n",
       "      <td>I</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1958-10-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>01035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000115065</td>\n",
       "      <td>730</td>\n",
       "      <td>JDNC</td>\n",
       "      <td>PERE</td>\n",
       "      <td>I</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1973-07-03</td>\n",
       "      <td>1975-04-30</td>\n",
       "      <td>02408</td>\n",
       "      <td>97101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000116620</td>\n",
       "      <td>732</td>\n",
       "      <td>JAP</td>\n",
       "      <td>PERE</td>\n",
       "      <td>F</td>\n",
       "      <td>2003-10-21</td>\n",
       "      <td>02408</td>\n",
       "      <td>1964-10-03</td>\n",
       "      <td>1967-06-23</td>\n",
       "      <td>02431</td>\n",
       "      <td>02124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000132137</td>\n",
       "      <td>736</td>\n",
       "      <td>JAP</td>\n",
       "      <td>MERE</td>\n",
       "      <td>M</td>\n",
       "      <td>1992-09-28</td>\n",
       "      <td>75110</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>1949-01-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02722</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000142987</td>\n",
       "      <td>737</td>\n",
       "      <td>JAP</td>\n",
       "      <td>PERE</td>\n",
       "      <td>I</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1968-04-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>03102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID_DIFF ID_EVT_DIFF EVT_TYPE OPE_TYPE ENF_IND_SEXE ENF_IND_NAI_DATE  \\\n",
       "0  0000079705         727      JAP     PERE            I       0000-00-00   \n",
       "1  0000115065         730     JDNC     PERE            I       0000-00-00   \n",
       "2  0000116620         732      JAP     PERE            F       2003-10-21   \n",
       "3  0000132137         736      JAP     MERE            M       1992-09-28   \n",
       "4  0000142987         737      JAP     PERE            I       0000-00-00   \n",
       "\n",
       "  ENF_IND_NAI_LIEU_DEPCOM PERE_IND_NAI_DATE MERE_IND_NAI_DATE  \\\n",
       "0                     NaN        1958-10-00        0000-00-00   \n",
       "1                     NaN        1973-07-03        1975-04-30   \n",
       "2                   02408        1964-10-03        1967-06-23   \n",
       "3                   75110        0000-00-00        1949-01-04   \n",
       "4                     NaN        1968-04-00        0000-00-00   \n",
       "\n",
       "  PERE_IND_NAI_LIEU_DEPCOM MERE_IND_NAI_LIEU_DEPCOM PERE_ADR_LIEU_DEPCOM  \\\n",
       "0                    01035                      NaN                  NaN   \n",
       "1                    02408                    97101                  NaN   \n",
       "2                    02431                    02124                  NaN   \n",
       "3                      NaN                    02722                  NaN   \n",
       "4                    03102                      NaN                  NaN   \n",
       "\n",
       "  MERE_ADR_LIEU_DEPCOM ADRDOMPAR PERE_NAT_CODE MERE_NAT_CODE PERE_CS_CODE  \\\n",
       "0                  NaN       NaN           NaN           NaN          NaN   \n",
       "1                  NaN       NaN           NaN           NaN          NaN   \n",
       "2                  NaN       NaN           NaN           NaN          NaN   \n",
       "3                  NaN       NaN           NaN           NaN          NaN   \n",
       "4                  NaN       NaN           NaN           NaN          NaN   \n",
       "\n",
       "  MERE_CS_CODE MAR_DATE MAR_LIEU_DEPCOM  ORIGINOM  ENF_GEMEL_INDIC  \\\n",
       "0          NaN      NaN             NaN       NaN              NaN   \n",
       "1          NaN      NaN             NaN       NaN              NaN   \n",
       "2          NaN      NaN             NaN       NaN              NaN   \n",
       "3          NaN      NaN             NaN       NaN              NaN   \n",
       "4          NaN      NaN             NaN       NaN              NaN   \n",
       "\n",
       "  CTX_MERE_VIVANT_ENF_PREC_NBR CTX_NAV_PREC_DATE  NB_EDP CTX_CATACC  \\\n",
       "0                          NaN               NaN       1        NaN   \n",
       "1                          NaN               NaN       1        NaN   \n",
       "2                          NaN               NaN       1        NaN   \n",
       "3                          NaN               NaN       1        NaN   \n",
       "4                          NaN               NaN       1        NaN   \n",
       "\n",
       "   CTX_ACC_ENF_NBR  I_ENF_IND_NAI_DATE  I_ENF_IND_SEXE  I_MAR_DATE  \\\n",
       "0              NaN                 NaN             NaN         NaN   \n",
       "1              NaN                 NaN             NaN         NaN   \n",
       "2              NaN                 NaN             NaN         NaN   \n",
       "3              NaN                 NaN             NaN         NaN   \n",
       "4              NaN                 NaN             NaN         NaN   \n",
       "\n",
       "   I_MAR_LIEU_DEPCOM  I_MERE_ADR_LIEU_DEPCOM  I_MERE_IND_NAI_DATE  \\\n",
       "0                NaN                     NaN                  NaN   \n",
       "1                NaN                     NaN                  NaN   \n",
       "2                NaN                     NaN                  NaN   \n",
       "3                NaN                     NaN                  NaN   \n",
       "4                NaN                     NaN                  NaN   \n",
       "\n",
       "   I_MERE_IND_NAI_LIEU_DEPCOM  I_MERE_NAT_CODE  I_MERE_CS_CODE  \\\n",
       "0                         NaN              NaN             NaN   \n",
       "1                         NaN              NaN             NaN   \n",
       "2                         NaN              NaN             NaN   \n",
       "3                         NaN              NaN             NaN   \n",
       "4                         NaN              NaN             NaN   \n",
       "\n",
       "   I_PERE_ADR_LIEU_DEPCOM  I_PERE_IND_NAI_DATE  I_PERE_IND_NAI_LIEU_DEPCOM  \\\n",
       "0                     NaN                  NaN                         NaN   \n",
       "1                     NaN                  NaN                         NaN   \n",
       "2                     NaN                  NaN                         NaN   \n",
       "3                     NaN                  NaN                         NaN   \n",
       "4                     NaN                  NaN                         NaN   \n",
       "\n",
       "   I_PERE_NAT_CODE  I_PERE_CS_CODE  \n",
       "0              NaN             NaN  \n",
       "1              NaN             NaN  \n",
       "2              NaN             NaN  \n",
       "3              NaN             NaN  \n",
       "4              NaN             NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_year = 2014\n",
    "\n",
    "# In[4]:\n",
    "year = 2014\n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "pd.set_option(\"display.max_columns\",200)\n",
    "\n",
    "\n",
    "store_path = '../../Data/hdf/edp_2015_final.h5'\n",
    "Store = pd.HDFStore(store_path)\n",
    "\n",
    "# # Inverstigation of EDP\n",
    "\n",
    "# Taken originaly from Table Find concubin + biologic child fiscal household\n",
    "# Data made in Isolate_concubin_with_child_under_majority\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pickle\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "\n",
    "def load_fisc_i_by_year(year = income_year):\n",
    "    df_fisci = pd.read_hdf(store_path, 'FISC_INDIVIDU_{}'.format(year))\n",
    "    return df_fisci\n",
    "def load_fisc_r_by_year(year = income_year):\n",
    "    df_fiscr = pd.read_hdf(store_path, 'FISC_REVENU_{}'.format(year))\n",
    "    return df_fiscr\n",
    "def load_fisc_l_by_year(year = income_year):\n",
    "    df_fiscr = pd.read_hdf(store_path, 'FISC_LOGEMENT_{}'.format(year))\n",
    "    return df_fiscr\n",
    "\n",
    "def load_df_fiscrevdet_by_year(year = income_year+1):\n",
    "    df_fiscrevdet = pd.read_hdf(store_path, 'FISC_REVDET_{}'.format(year))\n",
    "    return df_fiscrevdet\n",
    "\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "df_fisci = load_fisc_i_by_year(year = income_year)\n",
    "print df_fisci.shape\n",
    "\n",
    "\n",
    "import pickle\n",
    "keep = pickle.load(\n",
    "            open(u\"../../Programme/Pickle/final_select_rev_{}.p\".format(year), 'rb'))\n",
    "\n",
    "df_fisci = df_fisci[df_fisci.ID_FISC_LOG_DIFF.isin(keep)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "fisci_id_diff = df_fisci.ID_DIFF\n",
    "\n",
    "\n",
    "# #### TODO:  problème on a des individus qui ont deux identifiants fiscal individuel.\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "df_descendance = pd.read_hdf(store_path,\"DESCENDANCE\")\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "df_descendance.head()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1320391, 41)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_descendance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1290851, 41)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_descendance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_diff_descendance = pd.Series(descendance_ID_DIFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'id_diff_descendance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-d02ddc40cfd8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mid_diff_descendance\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid_diff_descendance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnumeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'id_diff_descendance' is not defined"
     ]
    }
   ],
   "source": [
    "id_diff_descendance[id_diff_descendance.str.isnumeric()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: X130113111",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-f4912b3b6fff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# In[13]:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdf_fisci\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'IS_IN_DESCENDANCE'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_fisci\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID_DIFF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdescendance_ID_DIFF\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"float\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\IMPTEMP_A_PACIFIC\\Desktop\\WinPython-64bit-2.7.10.2\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, raise_on_error, **kwargs)\u001b[0m\n\u001b[0;32m   2409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2410\u001b[0m         mgr = self._data.astype(\n\u001b[1;32m-> 2411\u001b[1;33m             dtype=dtype, copy=copy, raise_on_error=raise_on_error, **kwargs)\n\u001b[0m\u001b[0;32m   2412\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmgr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\IMPTEMP_A_PACIFIC\\Desktop\\WinPython-64bit-2.7.10.2\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[0;32m   2502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2503\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2504\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'astype'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2505\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2506\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\IMPTEMP_A_PACIFIC\\Desktop\\WinPython-64bit-2.7.10.2\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, axes, filter, do_integrity_check, **kwargs)\u001b[0m\n\u001b[0;32m   2457\u001b[0m                                                  copy=align_copy)\n\u001b[0;32m   2458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2459\u001b[1;33m             \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2461\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\IMPTEMP_A_PACIFIC\\Desktop\\WinPython-64bit-2.7.10.2\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, raise_on_error, values, **kwargs)\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_on_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m         return self._astype(dtype, copy=copy, raise_on_error=raise_on_error,\n\u001b[1;32m--> 373\u001b[1;33m                             values=values, **kwargs)\n\u001b[0m\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m     def _astype(self, dtype, copy=False, raise_on_error=True, values=None,\n",
      "\u001b[1;32mC:\\Users\\IMPTEMP_A_PACIFIC\\Desktop\\WinPython-64bit-2.7.10.2\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36m_astype\u001b[1;34m(self, dtype, copy, raise_on_error, values, klass, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m                 \u001b[1;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_astype_nansafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m             newb = make_block(values,\n",
      "\u001b[1;32mC:\\Users\\IMPTEMP_A_PACIFIC\\Desktop\\WinPython-64bit-2.7.10.2\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\pandas\\core\\common.pyc\u001b[0m in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy)\u001b[0m\n\u001b[0;32m   2732\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2733\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2734\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2735\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2736\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: X130113111"
     ]
    }
   ],
   "source": [
    "descendance_ID_DIFF = df_descendance.ID_DIFF.unique()\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "df_fisci['IS_IN_DESCENDANCE'] = df_fisci.ID_DIFF.isin(.astype(\"float\")).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(descendance_ID_DIFF[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    699691\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fisci.IS_IN_DESCENDANCE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 29)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_FISC_LOG_DIFF</th>\n",
       "      <th>ID_DIFF</th>\n",
       "      <th>NB_CHILD_IN_HOUSEHOLD</th>\n",
       "      <th>NB_NAISSANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ID_FISC_LOG_DIFF, ID_DIFF, NB_CHILD_IN_HOUSEHOLD, NB_NAISSANCE]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "df_fisci.groupby('ID_FISC_LOG_DIFF').sum()['IS_IN_DESCENDANCE'].value_counts()\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 87000 foyers avec au moins un individu EDP dans table naissance ou descendance.\n",
    "\n",
    "# ### Voir si enfants ou parents\n",
    "\n",
    "# Descendance, 90680 parents, 33 personnes à charges\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "df_fisci[df_fisci.IS_IN_DESCENDANCE.astype('bool')].TYPE_FISC.value_counts()\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "df_fisci_etat_c = df_fisci[df_fisci.IS_IN_DESCENDANCE.astype('bool')]\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "print(df_fisci_etat_c.shape)\n",
    "\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "id_diff_fisci_c = df_fisci_etat_c.ID_DIFF\n",
    "\n",
    "\n",
    "# Nombre de naissances repérées par ID_DIFF\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "df_descendance[\n",
    "    df_descendance.ID_DIFF.isin(id_diff_fisci_c)\n",
    "           ].groupby('ID_DIFF').count()[ 'ID_EVT_DIFF'].value_counts()\n",
    "\n",
    "\n",
    "# 45755 individus ont une naissance renseignée, 34000 en ont deux, 7374 en ont trois, 1393 en ont 4.\n",
    "\n",
    "# ##### Virer les observations contenant des enfants nais sans vie\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "df_descendance.EVT_TYPE.value_counts()\n",
    "\n",
    "\n",
    "# In[22]:\n",
    "\n",
    "df_descendance = df_descendance[~(df_descendance.EVT_TYPE == 'ESV')] #On gagne 269 ménages qui ont le même nombre d'enfants en faisant ça\n",
    "# On perd 377 ménages qui ont le nombre d'enfant inférieur au nombre de naissance.\n",
    "# On gagne 66 ménages qui ont le nombre d'enfant supérieur au nombre de naissance.\n",
    "\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "#df_descendance.EVT_TYPE.value_counts()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[24]:\n",
    "\n",
    "df_nb_naissance = df_descendance[df_descendance.ID_DIFF.isin(id_diff_fisci_c)\n",
    "                                ].groupby('ID_DIFF').count().reset_index()[['ID_DIFF','EVT_TYPE']]\n",
    "df_nb_naissance =  df_nb_naissance.rename(columns = {'EVT_TYPE' : 'NB_NAISSANCE'})\n",
    "df_nb_naissance.head()\n",
    "\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "nb_indiv_in_household = df_fisci.groupby('ID_FISC_LOG_DIFF' ).count()\n",
    "nb_indiv_in_household['ID_DIFF']  = df_fisci.groupby('ID_FISC_LOG_DIFF' ).first()\n",
    "\n",
    "\n",
    "# In[26]:\n",
    "\n",
    "nb_indiv_in_household = nb_indiv_in_household.reset_index()[['ID_FISC_LOG_DIFF','ID_DIFF','AN_FISC']]\n",
    "\n",
    "\n",
    "# In[27]:\n",
    "\n",
    "nb_indiv_in_household['NB_CHILD_IN_HOUSEHOLD'] = nb_indiv_in_household['AN_FISC'] - 2 \n",
    "\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "nb_indiv_in_household.drop('AN_FISC',1, inplace=True)\n",
    "\n",
    "\n",
    "# In[29]:\n",
    "\n",
    "merge = nb_indiv_in_household.merge(df_nb_naissance, on = 'ID_DIFF');merge.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\IMPTEMP_A_PACIFIC\\Desktop\\WinPython-64bit-2.7.10.2\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\IPython\\kernel\\zmq\\ipkernel.py\", line 181, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\IMPTEMP_A_PACIFIC\\Desktop\\WinPython-64bit-2.7.10.2\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2801, in run_cell\n    cell = self.input_transformer_manager.transform_cell(raw_cell)\n",
      "  File \"C:\\Users\\IMPTEMP_A_PACIFIC\\Desktop\\WinPython-64bit-2.7.10.2\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\IPython\\core\\inputsplitter.py\", line 597, in transform_cell\n    self.push(cell)\n",
      "  File \"C:\\Users\\IMPTEMP_A_PACIFIC\\Desktop\\WinPython-64bit-2.7.10.2\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\IPython\\core\\inputsplitter.py\", line 641, in push\n    out = self.push_line(line)\n",
      "  File \"C:\\Users\\IMPTEMP_A_PACIFIC\\Desktop\\WinPython-64bit-2.7.10.2\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\IPython\\core\\inputsplitter.py\", line 682, in push_line\n    return super(IPythonInputSplitter, self).push(line)\n",
      "  File \"C:\\Users\\IMPTEMP_A_PACIFIC\\Desktop\\WinPython-64bit-2.7.10.2\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\IPython\\core\\inputsplitter.py\", line 314, in push\n    self.code = self._compile(source, symbol=\"exec\")\n",
      "  File \"C:\\Users\\IMPTEMP_A_PACIFIC\\Desktop\\WinPython-64bit-2.7.10.2\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\codeop.py\", line 168, in __call__\n    return _maybe_compile(self.compiler, source, filename, symbol)\n",
      "  File \"C:\\Users\\IMPTEMP_A_PACIFIC\\Desktop\\WinPython-64bit-2.7.10.2\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\codeop.py\", line 92, in _maybe_compile\n    code2 = compiler(source + \"\\n\\n\", filename, symbol)\n",
      "  File \"C:\\Users\\IMPTEMP_A_PACIFIC\\Desktop\\WinPython-64bit-2.7.10.2\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\codeop.py\", line 135, in __call__\n    if codeob.co_flags & feature.compiler_flag:\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "from __future__ import division\n",
    "import pandas as pd ; pd.set_option(\"display.max_columns\",200)\n",
    "\n",
    "# # Inverstigation of EDP\n",
    "\n",
    "# Taken originaly from Table Find concubin + biologic child fiscal household\n",
    "# Data made in Isolate_concubin_with_child_under_majority\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pickle\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "Store\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "\n",
    "def create_data_year(income_year = 2014):\n",
    "    income_year = income_year\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def load_fisc_i_by_year(year = income_year):\n",
    "        df_fisci = pd.read_hdf(store_path, 'FISC_INDIVIDU_{}'.format(year))\n",
    "        return df_fisci\n",
    "    def load_fisc_r_by_year(year = income_year):\n",
    "        df_fiscr = pd.read_hdf(store_path, 'FISC_REVENU_{}'.format(year))\n",
    "        return df_fiscr\n",
    "    def load_fisc_l_by_year(year = income_year):\n",
    "        df_fiscr = pd.read_hdf(store_path, 'FISC_LOGEMENT_{}'.format(year))\n",
    "        return df_fiscr\n",
    "    \n",
    "    def load_df_fiscrevdet_by_year(year = income_year+1):\n",
    "        df_fiscrevdet = pd.read_hdf(store_path, 'FISC_REVDET_{}'.format(year))\n",
    "        return df_fiscrevdet\n",
    "\n",
    "\n",
    "\n",
    "    # In[9]:\n",
    "    \n",
    "    df_fisci = load_fisc_i_by_year(year = income_year)\n",
    "    print df_fisci.shape\n",
    "        \n",
    "    \n",
    "    import pickle\n",
    "    keep = pickle.load(\n",
    "                open(u\"./Programme/Pickle/final_select_rev_{}.p\".format(year), 'rb'))\n",
    "    \n",
    "    df_fisci = df_fisci[df_fisci.ID_FISC_LOG_DIFF.isin(keep)]\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    # In[9]:\n",
    "    \n",
    "    fisci_id_diff = df_fisci.ID_DIFF\n",
    "    \n",
    "    \n",
    "    # #### TODO:  problème on a des individus qui ont deux identifiants fiscal individuel.\n",
    "    \n",
    "    # In[10]:\n",
    "    \n",
    "    df_descendance = pd.read_hdf(store_path,\"DESCENDANCE\")\n",
    "    \n",
    "    \n",
    "    # In[11]:\n",
    "    \n",
    "    df_descendance.head()\n",
    "    \n",
    "    \n",
    "    # In[ ]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # In[12]:\n",
    "    \n",
    "    descendance_ID_DIFF = df_descendance.ID_DIFF.unique()\n",
    "    \n",
    "    \n",
    "    # In[ ]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # In[13]:\n",
    "    \n",
    "    df_fisci['IS_IN_DESCENDANCE'] = df_fisci.ID_DIFF.isin(descendance_ID_DIFF).astype('int')\n",
    "    \n",
    "    \n",
    "    # In[14]:\n",
    "    \n",
    "    df_fisci.groupby('ID_FISC_LOG_DIFF').sum()['IS_IN_DESCENDANCE'].value_counts()\n",
    "    \n",
    "    \n",
    "    # In[15]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # 87000 foyers avec au moins un individu EDP dans table naissance ou descendance.\n",
    "    \n",
    "    # ### Voir si enfants ou parents\n",
    "    \n",
    "    # Descendance, 90680 parents, 33 personnes à charges\n",
    "    \n",
    "    # In[16]:\n",
    "    \n",
    "    df_fisci[df_fisci.IS_IN_DESCENDANCE.astype('bool')].TYPE_FISC.value_counts()\n",
    "    \n",
    "    \n",
    "    # In[17]:\n",
    "    \n",
    "    df_fisci_etat_c = df_fisci[df_fisci.IS_IN_DESCENDANCE.astype('bool')]\n",
    "    \n",
    "    \n",
    "    # In[18]:\n",
    "    \n",
    "    df_fisci_etat_c.shape\n",
    "    \n",
    "    \n",
    "    # In[19]:\n",
    "    \n",
    "    id_diff_fisci_c = df_fisci_etat_c.ID_DIFF\n",
    "    \n",
    "    \n",
    "    # Nombre de naissances repérées par ID_DIFF\n",
    "    \n",
    "    # In[20]:\n",
    "    \n",
    "    df_descendance[\n",
    "        df_descendance.ID_DIFF.isin(id_diff_fisci_c)\n",
    "               ].groupby('ID_DIFF').count()[ 'ID_EVT_DIFF'].value_counts()\n",
    "    \n",
    "    \n",
    "    # 45755 individus ont une naissance renseignée, 34000 en ont deux, 7374 en ont trois, 1393 en ont 4.\n",
    "    \n",
    "    # ##### Virer les observations contenant des enfants nais sans vie\n",
    "    \n",
    "    # In[21]:\n",
    "    \n",
    "    df_descendance.EVT_TYPE.value_counts()\n",
    "    \n",
    "    \n",
    "    # In[22]:\n",
    "    \n",
    "    df_descendance = df_descendance[~(df_descendance.EVT_TYPE == 'ESV')] #On gagne 269 ménages qui ont le même nombre d'enfants en faisant ça\n",
    "    # On perd 377 ménages qui ont le nombre d'enfant inférieur au nombre de naissance.\n",
    "    # On gagne 66 ménages qui ont le nombre d'enfant supérieur au nombre de naissance.\n",
    "    \n",
    "    \n",
    "    # In[23]:\n",
    "    \n",
    "    #df_descendance.EVT_TYPE.value_counts()\n",
    "    \n",
    "    \n",
    "    # In[ ]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # In[24]:\n",
    "    \n",
    "    df_nb_naissance = df_descendance[df_descendance.ID_DIFF.isin(id_diff_fisci_c)\n",
    "                                    ].groupby('ID_DIFF').count().reset_index()[['ID_DIFF','EVT_TYPE']]\n",
    "    df_nb_naissance =  df_nb_naissance.rename(columns = {'EVT_TYPE' : 'NB_NAISSANCE'})\n",
    "    df_nb_naissance.head()\n",
    "    \n",
    "    \n",
    "    # In[25]:\n",
    "    \n",
    "    nb_indiv_in_household = df_fisci.groupby('ID_FISC_LOG_DIFF' ).count()\n",
    "    nb_indiv_in_household['ID_DIFF']  = df_fisci.groupby('ID_FISC_LOG_DIFF' ).first()\n",
    "    \n",
    "    \n",
    "    # In[26]:\n",
    "    \n",
    "    nb_indiv_in_household = nb_indiv_in_household.reset_index()[['ID_FISC_LOG_DIFF','ID_DIFF','AN_FISC']]\n",
    "    \n",
    "    \n",
    "    # In[27]:\n",
    "    \n",
    "    nb_indiv_in_household['NB_CHILD_IN_HOUSEHOLD'] = nb_indiv_in_household['AN_FISC'] - 2 \n",
    "    \n",
    "    \n",
    "    # In[28]:\n",
    "    \n",
    "    nb_indiv_in_household.drop('AN_FISC',1, inplace=True)\n",
    "    \n",
    "    \n",
    "    # In[29]:\n",
    "    \n",
    "    merge = nb_indiv_in_household.merge(df_nb_naissance, on = 'ID_DIFF');merge.head()\n",
    "    \n",
    "    \n",
    "    # In[ ]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # In[30]:\n",
    "    \n",
    "    print (merge.NB_CHILD_IN_HOUSEHOLD == merge.NB_NAISSANCE).value_counts()\n",
    "    print (merge.NB_CHILD_IN_HOUSEHOLD == merge.NB_NAISSANCE).value_counts(normalize = True)\n",
    "    \n",
    "    \n",
    "    # 36% des ménages n'ont pas le même nombre de naissance dans la base naissance et le même nombre d'enfants dans le logement fiscal.\n",
    "    # Pourquoi ? Sous déclaration ?\n",
    "    \n",
    "    # In[31]:\n",
    "    \n",
    "    8532 - 8909\n",
    "    \n",
    "    \n",
    "    # In[32]:\n",
    "    \n",
    "    (merge.NB_CHILD_IN_HOUSEHOLD < merge.NB_NAISSANCE).value_counts()\n",
    "    \n",
    "    \n",
    "    # Hypothèses : enfants morts, enfant parti dans autre foyer, trou de déclaration (trou de 1982 à 1997)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # In[34]:\n",
    "    \n",
    "    (merge.NB_CHILD_IN_HOUSEHOLD > merge.NB_NAISSANCE).value_counts()\n",
    "    \n",
    "    \n",
    "    # In[35]:\n",
    "    \n",
    "    df_fisci[df_fisci.TYPE_FISC == '1'].JNAIS.isnull().value_counts()\n",
    "    \n",
    "    \n",
    "    # Jours de naissance renseigné pour tout les parents\n",
    "    \n",
    "    # In[36]:\n",
    "    \n",
    "    df_fisci.T_CHARGE.value_counts()\n",
    "    \n",
    "    \n",
    "    # T_CHARGE : Code situation des personnes à charge. F : normal. G: Enfant à charge titulaire de la carte d'invalidité.\n",
    "    # \n",
    "    # On a pas d'enfant en garde alternée dans le sample (bon signal).\n",
    "    \n",
    "    # In[ ]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # ## Début Zap 1\n",
    "    \n",
    "    # In[37]:\n",
    "    \n",
    "    df_descendance[~df_descendance.CTX_NAV_PREC_DATE.isnull()].ENF_IND_NAI_DATE.str[:4].value_counts().head()\n",
    "    \n",
    "    \n",
    "    # In[38]:\n",
    "    \n",
    "    hello = df_descendance[df_descendance.ID_DIFF.isin(id_diff_fisci_c)\n",
    "                  ].groupby('ID_DIFF').CTX_NAV_PREC_DATE.apply(list)\n",
    "    \n",
    "    \n",
    "    # In[39]:\n",
    "    \n",
    "    hello.shape\n",
    "    \n",
    "    \n",
    "    # In[40]:\n",
    "    \n",
    "    hello.head()\n",
    "    \n",
    "    \n",
    "    # In[ ]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # On garde dans la table descendance que les observations ou :\n",
    "    # - l'id_diff est dans fisci\n",
    "    # - \n",
    "    \n",
    "    # In[41]:\n",
    "    \n",
    "    df = df_descendance[\n",
    "        df_descendance.ID_DIFF.isin(id_diff_fisci_c) #dans fisci\n",
    "                  ].groupby('ID_DIFF').first().reset_index()\n",
    "    \n",
    "    \n",
    "    # In[ ]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # In[ ]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # In[ ]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # In[42]:\n",
    "    \n",
    "    hello = pd.DataFrame(hello).reset_index();hello.head()\n",
    "    \n",
    "    \n",
    "    # In[43]:\n",
    "    \n",
    "    df = df.merge(hello,on='ID_DIFF')\n",
    "    \n",
    "    \n",
    "    # In[44]:\n",
    "    \n",
    "    df.columns\n",
    "    \n",
    "    \n",
    "    # In[ ]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # In[45]:\n",
    "    \n",
    "    df = df[[  u'CTX_NAV_PREC_DATE_y','CTX_ACC_ENF_NBR','CTX_MERE_VIVANT_ENF_PREC_NBR',\n",
    "        u'ID_DIFF', u'ID_EVT_DIFF', u'EVT_TYPE', u'OPE_TYPE', u'ENF_IND_SEXE',\n",
    "           u'ENF_IND_NAI_DATE', u'ENF_IND_NAI_LIEU_DEPCOM', u'PERE_IND_NAI_DATE',\n",
    "           u'MERE_IND_NAI_DATE', u'PERE_IND_NAI_LIEU_DEPCOM',\n",
    "           u'MERE_IND_NAI_LIEU_DEPCOM', u'PERE_ADR_LIEU_DEPCOM',\n",
    "           u'MERE_ADR_LIEU_DEPCOM', u'ADRDOMPAR', u'PERE_NAT_CODE',\n",
    "           u'MERE_NAT_CODE', u'PERE_CS_CODE', u'MERE_CS_CODE', u'MAR_DATE',\n",
    "           u'MAR_LIEU_DEPCOM', u'ORIGINOM', u'ENF_GEMEL_INDIC',\n",
    "           u'NB_EDP',\n",
    "           u'CTX_CATACC', u'CTX_ACC_ENF_NBR', u'I_ENF_IND_NAI_DATE',\n",
    "           u'I_ENF_IND_SEXE', u'I_MAR_DATE', u'I_MAR_LIEU_DEPCOM',\n",
    "           u'I_MERE_ADR_LIEU_DEPCOM', u'I_MERE_IND_NAI_DATE',\n",
    "           u'I_MERE_IND_NAI_LIEU_DEPCOM', u'I_MERE_NAT_CODE', u'I_MERE_CS_CODE',\n",
    "           u'I_PERE_ADR_LIEU_DEPCOM', u'I_PERE_IND_NAI_DATE',\n",
    "           u'I_PERE_IND_NAI_LIEU_DEPCOM', u'I_PERE_NAT_CODE', u'I_PERE_CS_CODE',\n",
    "           ]]\n",
    "    \n",
    "    \n",
    "    # In[46]:\n",
    "    \n",
    "    df.head(5)\n",
    "    \n",
    "    \n",
    "    # Technique\n",
    "    \n",
    "    # In[ ]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # In[ ]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # In[ ]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # In[ ]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # In[ ]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Question : pourquoi le premier CTX_NAV_Prec_date pas toujours nan ou 0000 ?\n",
    "    \n",
    "    # In[ ]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # In[ ]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # In[ ]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # In[47]:\n",
    "    \n",
    "    df.CTX_MERE_VIVANT_ENF_PREC_NBR.value_counts(dropna = False).head()\n",
    "    \n",
    "    \n",
    "    # In[48]:\n",
    "    \n",
    "    df[['OPE_TYPE','CTX_MERE_VIVANT_ENF_PREC_NBR' ]].head()\n",
    "    \n",
    "    \n",
    "    # In[49]:\n",
    "    \n",
    "    import numpy as np\n",
    "    \n",
    "    \n",
    "    # In[ ]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # In[50]:\n",
    "    \n",
    "    df[['OPE_TYPE','CTX_MERE_VIVANT_ENF_PREC_NBR' \n",
    "       ]].pivot_table( columns = ['CTX_MERE_VIVANT_ENF_PREC_NBR'], \n",
    "                      index=['OPE_TYPE'],\n",
    "                      aggfunc = len, fill_value=0)\n",
    "    \n",
    "    \n",
    "    # In[51]:\n",
    "    \n",
    "    df2  = df[['OPE_TYPE','CTX_MERE_VIVANT_ENF_PREC_NBR' ]]\n",
    "    \n",
    "    \n",
    "    # In[52]:\n",
    "    \n",
    "    df2[(df2.CTX_MERE_VIVANT_ENF_PREC_NBR == '*')&(df2.OPE_TYPE == 'MERE' )].shape\n",
    "    \n",
    "    \n",
    "    # In[53]:\n",
    "    \n",
    "    df2.loc[ df2.CTX_MERE_VIVANT_ENF_PREC_NBR == '*', 'CTX_MERE_VIVANT_ENF_PREC_NBR'] = 0\n",
    "    \n",
    "    \n",
    "    # In[54]:\n",
    "    \n",
    "    df2.loc[ df2.CTX_MERE_VIVANT_ENF_PREC_NBR.isnull(), 'CTX_MERE_VIVANT_ENF_PREC_NBR'] = 0\n",
    "    \n",
    "    \n",
    "    # In[55]:\n",
    "    \n",
    "    df2['CTX_MERE_VIVANT_ENF_PREC_NBR'] = df2.CTX_MERE_VIVANT_ENF_PREC_NBR.astype('int32')\n",
    "    \n",
    "    \n",
    "    # In[56]:\n",
    "    \n",
    "    df2.head()\n",
    "    \n",
    "    \n",
    "    # In[57]:\n",
    "    \n",
    "    df2[['OPE_TYPE','CTX_MERE_VIVANT_ENF_PREC_NBR' \n",
    "       ]].pivot_table( columns = ['CTX_MERE_VIVANT_ENF_PREC_NBR'], \n",
    "                      index=['OPE_TYPE'],\n",
    "                      aggfunc = len, fill_value=0)\n",
    "    \n",
    "    \n",
    "    # In[58]:\n",
    "    \n",
    "    df['NB_CTX_NAV_PREC_DATE'] = df.CTX_NAV_PREC_DATE_y.apply(lambda x: len(x))\n",
    "    \n",
    "    \n",
    "    # In[59]:\n",
    "    \n",
    "    df[['NB_CTX_NAV_PREC_DATE', u'CTX_NAV_PREC_DATE_y','CTX_ACC_ENF_NBR','CTX_MERE_VIVANT_ENF_PREC_NBR',u'OPE_TYPE',\n",
    "        u'ID_DIFF', u'ID_EVT_DIFF', u'EVT_TYPE',  u'ENF_IND_SEXE',\n",
    "           u'ENF_IND_NAI_DATE']].head()\n",
    "    \n",
    "    \n",
    "    # TODO : investiguer un peu plus les rangs de naissance, mais ça semble assez peu prometteur...\n",
    "    \n",
    "    # ## Fin Zap 1\n",
    "    \n",
    "    # ### Regarder les dates de naissances parents/enfants\n",
    "    \n",
    "    # Stratégie :\n",
    "    # \n",
    "    # Si enfant EDP --> 2 bdates naissance parents --> ok paternité. Par contre difficile de déterminer pour frere et soeurs.\n",
    "    # \n",
    "    # Si non EDP & 1 des deux parents EDP -- > 2 dates naissances parents --> ok !\n",
    "    \n",
    "    # In[ ]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # On prends que les parents qui sont EDP.\n",
    "    \n",
    "    # In[60]:\n",
    "    \n",
    "    df_fisci_declar_edp = df_fisci[(df_fisci.TYPE_FISC=='1')&\n",
    "                  (~df_fisci.ID_DIFF.isnull())]\n",
    "    \n",
    "    \n",
    "    # In[61]:\n",
    "    \n",
    "    df_fisci_declar_edp.shape\n",
    "    \n",
    "    \n",
    "    # In[62]:\n",
    "    \n",
    "    df_fisci_declar_edp.ID_DIFF.nunique()\n",
    "    \n",
    "    \n",
    "    # ### Attention on a des individus en double.\n",
    "    \n",
    "    # TODO : les enlever, par contre, si on les enlèves à la bourrin on peut casser la structure du ménage...\n",
    "    \n",
    "    # In[ ]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # In[63]:\n",
    "    \n",
    "    id_diff = df_fisci_declar_edp.ID_DIFF\n",
    "    \n",
    "    \n",
    "    # In[64]:\n",
    "    \n",
    "    df_descendance[df_descendance.ID_DIFF.isin(id_diff)].ID_DIFF.unique().shape\n",
    "    \n",
    "    \n",
    "    # Parmis les 115367 parents EDP, seul 89520 figurent dans la base descendance, soit 77% .\n",
    "    # Pourquoi ? Parents non biologiques ?\n",
    "    \n",
    "    # On va vérifier que les dates de naissance des parents sont les mêmes que les enfants.\n",
    "    \n",
    "    # In[65]:\n",
    "    \n",
    "    df_descendance_select = df_descendance[df_descendance.ID_DIFF.isin(id_diff)] #Prends que les parends edp\n",
    "    \n",
    "    #♣Transforme les dates de naissances en format date\n",
    "    # In[66]:\n",
    "    \n",
    "    df_descendance_select['PERE_IND_NAI_DATE'] = pd.to_datetime(\n",
    "        df_descendance_select['PERE_IND_NAI_DATE'], infer_datetime_format=True, coerce=True\n",
    "        )\n",
    "    df_descendance_select['MERE_IND_NAI_DATE'] = pd.to_datetime(\n",
    "        df_descendance_select['MERE_IND_NAI_DATE'], infer_datetime_format=True, coerce=True\n",
    "        )\n",
    "        \n",
    "    df_descendance_select['ENF_IND_NAI_DATE'] = pd.to_datetime(\n",
    "        df_descendance_select['ENF_IND_NAI_DATE'], infer_datetime_format=True, coerce=True\n",
    "        )\n",
    "    \n",
    "    \n",
    "    # In[ ]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # In[67]:\n",
    "    \n",
    "    print df_descendance_select.PERE_IND_NAI_DATE.isnull().value_counts()\n",
    "    print df_descendance_select.MERE_IND_NAI_DATE.isnull().value_counts()\n",
    "    print df_descendance_select.ENF_IND_NAI_DATE.isnull().value_counts()\n",
    "    print df_descendance_select.PERE_IND_NAI_DATE.isnull().value_counts(normalize = True)\n",
    "    print df_descendance_select.MERE_IND_NAI_DATE.isnull().value_counts(normalize = True)\n",
    "    print df_descendance_select.ENF_IND_NAI_DATE.isnull().value_counts(normalize = True)\n",
    "    \n",
    "    \n",
    "    # 3%  des pères et 0.3% des mères n'ont pas la date de naissance renseignée, pourquoi ? TODO.\n",
    "    \n",
    "    # On vire tout les logement fiscaux dont un enfant d'un ménage 'parent EDP' n'a pas la date du père ou de la mère renseignée.\n",
    "    \n",
    "    # In[68]:\n",
    "    \n",
    "    select_id_diff = df_descendance_select[(df_descendance_select.PERE_IND_NAI_DATE.isnull())|\n",
    "                                          (df_descendance_select.MERE_IND_NAI_DATE.isnull())|\n",
    "                                           (df_descendance_select.ENF_IND_NAI_DATE.isnull())\n",
    "                                           ].ID_DIFF\n",
    "    \n",
    "    \n",
    "    # In[69]:\n",
    "    \n",
    "    temp_df = df_fisci_declar_edp[df_fisci_declar_edp.ID_DIFF.isin(select_id_diff)].groupby('ID_FISC_LOG_DIFF').count()\n",
    "    \n",
    "    \n",
    "    # In[70]:\n",
    "    \n",
    "    temp_df.reset_index(inplace = True)\n",
    "    \n",
    "    \n",
    "    # In[71]:\n",
    "    \n",
    "    to_drop_id_fisc_log = temp_df.ID_FISC_LOG_DIFF\n",
    "    \n",
    "    \n",
    "    # In[72]:\n",
    "    \n",
    "    df_fisci_declar_date_parents = df_fisci_declar_edp[~df_fisci_declar_edp.ID_FISC_LOG_DIFF.isin(to_drop_id_fisc_log)] #Vire les \n",
    "    #logements fiscaux dont la date d'un des deux parent (ou de l'enfant) n'est pas renseigne\n",
    "    \n",
    "    \n",
    "    # In[73]:\n",
    "    \n",
    "    df_fisci_declar_date_parents.head()\n",
    "    \n",
    "    \n",
    "    # A faire : voir si on a la même date de naissance des enfants\n",
    "    \n",
    "    # df_select_2 : on garde que les ménages ou la date des parents et des enfants est renseigné dans l'état civil (fille de df_select ou on ne gardait que les déclarants EDP de fisci qui étaient dans DESCENDANCE 89000 individus.)\n",
    "    \n",
    "    # In[74]:\n",
    "    \n",
    "    df_descendance_select_2 = df_descendance[\n",
    "        df_descendance.ID_DIFF.isin(df_fisci_declar_date_parents.ID_DIFF)]\n",
    "    \n",
    "    \n",
    "    # In[75]:\n",
    "    \n",
    "    df_descendance_select_2.shape\n",
    "    \n",
    "    \n",
    "    # In[76]:\n",
    "    \n",
    "    df_descendance_select_2.ENF_IND_NAI_DATE.str[:4].value_counts().head(12)\n",
    "    \n",
    "    \n",
    "    # En 2004 les jours EDP on été élargi de 4 à 16. Univquement les naissance d'après 2004 rentre en compte pour ces 12/16 de la pop.\n",
    "    # (D'où absence d'enfants dans de nombreux foyers).\n",
    "    # \n",
    "    \n",
    "    # In[77]:\n",
    "    \n",
    "    df_descendance_select_2[\n",
    "        df_descendance_select_2.ENF_IND_NAI_DATE.str[:4]=='2015'].ENF_IND_NAI_DATE.str[5:7].value_counts()\n",
    "    \n",
    "    \n",
    "    # In[78]:\n",
    "    \n",
    "    df_descendance.ENF_IND_NAI_DATE.str[:4].value_counts().head(13)\n",
    "    \n",
    "    \n",
    "    # On a pas le même nopmbre de naissance en fonction de l'année. Pourquoi ?\n",
    "    \n",
    "    # Lorsque l'EDP a été élargi à de nouveaux jours, l'EDP a débuté les trajectoires des nouveaux arrivants par le premier événement reçu par l'état civil ou le recensement. Leur\n",
    "    # trajectoire n'a pas été complétée par les événements antérieurs à la date de leur entrée dans l'EDP. Notamment, on ne dispose pas pour eux des bulletins de naissance de\n",
    "    # leurs enfants antérieurs à leur entrée dans l'EDP.\n",
    "    \n",
    "    # TODO: remarques au dessus.\n",
    "    \n",
    "    # In[79]:\n",
    "    \n",
    "    df_descendance_select_2.ENF_IND_NAI_DATE.str[0:4].value_counts().head(11)\n",
    "    \n",
    "    \n",
    "    # On a pas le meme nombre pas an car les logements fiscaux qui existent en 2015 n'existaient pas forcément avant.\n",
    "    # Les nouveaux logements fiscaux sont plus jeune, et ont donc des enfants qui sont plus jeune.\n",
    "    # Normalement pas de biais de sélection.\n",
    "    \n",
    "    # ### Regarder si on a la même année de naissance pour tout les enfants + voir si date de naissance des parents est la même.\n",
    "    \n",
    "    # In[80]:\n",
    "    \n",
    "    df_descendance_select_2.groupby('ID_DIFF').ID_DIFF.count().head()\n",
    "    \n",
    "    \n",
    "    # In[81]:\n",
    "    \n",
    "    df_descendance_select_2.groupby('ID_DIFF').ID_DIFF.count().value_counts()\n",
    "    \n",
    "    \n",
    "    # In[82]:\n",
    "    \n",
    "    df_nb_descendant_dans_descendance_by_id_diff = pd.DataFrame(df_descendance_select_2.groupby('ID_DIFF').ID_DIFF.count())\n",
    "    df_nb_descendant_dans_descendance_by_id_diff = df_nb_descendant_dans_descendance_by_id_diff.rename(\n",
    "                                columns = {'ID_DIFF' : 'NB_NAISSANCE'}).reset_index()\n",
    "    \n",
    "    \n",
    "    # In[83]:\n",
    "    \n",
    "    #pd.merge(df_fisci,df_nombre_descendant_by_id_diff, on = 'ID_DIFF')\n",
    "    \n",
    "    \n",
    "    # In[84]:\n",
    "    \n",
    "    #(df_descendance_select_2.PERE_IND_NAI_DATE == ANAIS + MNAIS+JNAIS) &(fisci.sexe == 1)\n",
    "    \n",
    "    \n",
    "    # On crée une variable date de naissance à partir de l'année du mois et du jour.\n",
    "    \n",
    "    # In[85]:\n",
    "    \n",
    "    date_naissance = pd.to_datetime((df_fisci.ANAIS.apply(\n",
    "                                        lambda x: x.astype('str').replace('.0',''))+'-'+\n",
    "                                      df_fisci.MNAIS.apply(\n",
    "                                        lambda x: x.astype('str').replace('.0',''))+'-'+\n",
    "                                      df_fisci.JNAIS.apply(\n",
    "                                        lambda x: x.astype('str').replace('.0',''))), \n",
    "                                                   coerce=True, infer_datetime_format=True)\n",
    "    # In[86]:\n",
    "    \n",
    "    df_fisci['Date_Naissance'] = date_naissance\n",
    "    df_fisci_date_naissance = df_fisci\n",
    "    \n",
    "    \n",
    "    # In[87]:\n",
    "    \n",
    "    df_fisci_date_naissance['SEXE'\n",
    "        ]=df_fisci_date_naissance.SEXE.astype('float')\n",
    "    \n",
    "    \n",
    "    # In[ ]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # In[88]:\n",
    "    \n",
    "    ((df_fisci_date_naissance.SEXE == 1) & \n",
    "     (df_fisci_date_naissance.TYPE_FISC == '1')).value_counts()\n",
    "     \n",
    "    \n",
    "    \n",
    "    # On a 180090 père déclarant dans la table fisci_final\n",
    "    \n",
    "    # In[89]:\n",
    "    \n",
    "    ((df_fisci_date_naissance.SEXE == 2) & \n",
    "     (df_fisci_date_naissance.TYPE_FISC == '1')).value_counts()\n",
    "    \n",
    "    \n",
    "    # Et  180518 mère délcante \n",
    "    \n",
    "    # In[90]:\n",
    "    \n",
    "    df_fisci_date_naissance[((df_fisci_date_naissance.SEXE == 1) & \n",
    "     (df_fisci_date_naissance.TYPE_FISC == '1'))].Date_Naissance.isnull().value_counts()\n",
    "    \n",
    "    \n",
    "    # TODO : Gerer les 31 gus qui ont pas leur date de naissance renseignée\n",
    "    \n",
    "    # In[ ]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # On met la date de naissance du père et de la mère dans fisci\n",
    "    \n",
    "    # In[91]:\n",
    "    \n",
    "    df_fisci_date_naissance['Date_Naissance_Pere_fisci'] = df_fisci_date_naissance[((df_fisci_date_naissance.SEXE == 1) & \n",
    "     (df_fisci_date_naissance.TYPE_FISC == '1'))].Date_Naissance\n",
    "    df_fisci_date_naissance['Date_Naissance_Mere_fisci'] = df_fisci_date_naissance[((df_fisci_date_naissance.SEXE == 2) & \n",
    "     (df_fisci_date_naissance.TYPE_FISC == '1'))].Date_Naissance\n",
    "    \n",
    "    \n",
    "    # In[92]:\n",
    "    \n",
    "    df_fisci_date_naissance[['ID_FISC_LOG_DIFF','Date_Naissance_Pere_fisci', 'Date_Naissance_Mere_fisci',\n",
    "                                   'TYPE_FISC', 'ANAIS', 'SEXE']].head()\n",
    "    \n",
    "    \n",
    "    # On met ensuite la date de naissance des parents de chaque logement fiscal.\n",
    "    \n",
    "    # In[93]:\n",
    "    \n",
    "    grpby_pere = df_fisci_date_naissance.sort('Date_Naissance_Pere_fisci').groupby('ID_FISC_LOG_DIFF').first(\n",
    "        )['Date_Naissance_Pere_fisci']\n",
    "    \n",
    "    \n",
    "    # In[94]:\n",
    "    \n",
    "    grpby_mere = df_fisci_date_naissance.sort('Date_Naissance_Mere_fisci').groupby('ID_FISC_LOG_DIFF').first(\n",
    "        )['Date_Naissance_Mere_fisci']\n",
    "    \n",
    "    \n",
    "    # In[95]:\n",
    "    \n",
    "    df_date_naissance = pd.merge(pd.DataFrame(grpby_pere).reset_index(), pd.DataFrame(grpby_mere).reset_index(),\n",
    "             on='ID_FISC_LOG_DIFF')\n",
    "    \n",
    "    \n",
    "    # In[96]:\n",
    "    \n",
    "    df_date_naissance.head()\n",
    "    \n",
    "    \n",
    "    # On merge a fici_final pour avoir la date de naissance des deux déclarants dans chaque fisci final\n",
    "    \n",
    "    # In[97]:\n",
    "    \n",
    "    #verifier si c'est le bon df à prendre.\n",
    "    df_fisci_date_naissance = pd.merge(df_fisci, df_date_naissance, on='ID_FISC_LOG_DIFF')\n",
    "    \n",
    "    \n",
    "    # In[98]:\n",
    "    \n",
    "    df_fisci_date_naissance[['ID_FISC_LOG_DIFF','Date_Naissance','Date_Naissance_Pere_fisci_y',\n",
    "                                                                      'Date_Naissance_Mere_fisci_y']].head(9)\n",
    "    \n",
    "    \n",
    "    # In[99]:\n",
    "    \n",
    "    print df_fisci_date_naissance.shape\n",
    "    print df_fisci.shape\n",
    "    \n",
    "    \n",
    "    # On a bien juste ajouté les deux dates de naissance à chaque logement.\n",
    "    \n",
    "    \n",
    "    \n",
    "    # In[100]:\n",
    "    \n",
    "    grpby = df_fisci_date_naissance.groupby('ID_FISC_LOG_DIFF').first().ID_DIFF.reset_index()\n",
    "    \n",
    "    \n",
    "    # In[101]:\n",
    "    \n",
    "    merged = pd.merge(df_fisci_date_naissance,grpby, on ='ID_FISC_LOG_DIFF', how = 'left'); print merged.shape\n",
    "    \n",
    "    \n",
    "    # In[102]:\n",
    "    \n",
    "    df_fisci.shape\n",
    "    \n",
    "    \n",
    "    # In[103]:\n",
    "    \n",
    "    merged['ID_DIFF'] = merged['ID_DIFF_y']\n",
    "    \n",
    "    \n",
    "    # In[104]:\n",
    "    \n",
    "    merged.shape\n",
    "    \n",
    "    \n",
    "    # In[105]:\n",
    "    \n",
    "    merged['Id_fisc'] = merged['ID_FISC_FOY_DIFF'].astype('str')+ merged['ORDREFIP']+ merged['TYPE_FISC']\n",
    "    \n",
    "    \n",
    "    # In[106]:\n",
    "    \n",
    "    merged.Id_fisc.drop_duplicates(inplace=True, take_last = True)\n",
    "    \n",
    "    \n",
    "    # In[107]:\n",
    "    \n",
    "    merged.Id_fisc.unique().shape\n",
    "    \n",
    "    \n",
    "    # On a bient tout le individus fiscaux qui ont un identifiant unique (meme shape)\n",
    "    \n",
    "    # In[108]:\n",
    "    \n",
    "    merged.shape\n",
    "    \n",
    "    \n",
    "    # In[109]:\n",
    "    \n",
    "    merged.columns\n",
    "    \n",
    "    \n",
    "    # In[110]:\n",
    "    \n",
    "    merged.groupby('ID_FISC_LOG_DIFF').sum().IS_IN_DESCENDANCE.value_counts()\n",
    "    \n",
    "    \n",
    "    # 91446 logements fiscaux n'ayant pas d'évènement de naissance dans la table descendance.\n",
    "    # 84908 ont un seul individu EDP, 2838 en ont deux. Ceux qui en ont trois ou 4 sont les enfants des parents qui ont eu des enfants.\n",
    "    \n",
    "    # On merge la table descendance contenant que les obs où tout les individus ont leur date de naissance renseignée.\n",
    "    # \n",
    "    # \n",
    "    # df_select_2 : on garde que les ménages ou la date des parents et des enfants est renseigné dans l'état civil (fille de df_select ou on ne gardait que les déclarants EDP de fisci qui étaient dans DESCENDANCE 89000 individus.)\n",
    "    \n",
    "    # In[111]:\n",
    "    \n",
    "    df_descendance_select_2.columns\n",
    "    \n",
    "    \n",
    "    # In[ ]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # In[112]:\n",
    "    \n",
    "    df_descend_fisci = df_descendance_select_2.merge(merged, on = 'ID_DIFF', how = 'right')\n",
    "    \n",
    "    \n",
    "    # In[113]:\n",
    "    \n",
    "    merged.shape\n",
    "    \n",
    "    \n",
    "    # In[114]:\n",
    "    \n",
    "    df_descend_fisci.shape\n",
    "    \n",
    "    \n",
    "    # In[ ]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # In[115]:\n",
    "    \n",
    "    selected_columns = ['ID_FISC_LOG_DIFF', 'ID_DIFF', u'ENF_IND_NAI_DATE', 'ANAIS','JNAIS', 'Id_fisc']\n",
    "    \n",
    "    \n",
    "    # In[116]:\n",
    "    \n",
    "    df_descend_fisci[selected_columns].sort(['ID_FISC_LOG_DIFF', 'ANAIS'])\n",
    "    \n",
    "    \n",
    "    # In[117]:\n",
    "    \n",
    "    df_descend_fisci[(df_descend_fisci.ANAIS == df_descend_fisci.ENF_IND_NAI_DATE.str[0:4].astype('float'))][selected_columns].head()\n",
    "    \n",
    "    \n",
    "    # In[118]:\n",
    "    \n",
    "    df_descend_fisci['Id_fisc'] = df_descend_fisci['ID_FISC_FOY_DIFF'].astype('str')+ df_descend_fisci['ORDREFIP']+ df_descend_fisci['TYPE_FISC']\n",
    "    \n",
    "    \n",
    "    # In[119]:\n",
    "    \n",
    "    df_descend_fisci['Birth_date_matched'] = False\n",
    "    \n",
    "    \n",
    "    # In[120]:\n",
    "    \n",
    "    selected_columns.extend(('Birth_date_matched','TYPE_FISC'))\n",
    "    \n",
    "    \n",
    "    # In[121]:\n",
    "    \n",
    "    df_descend_fisci.TYPE_FISC.value_counts()\n",
    "    \n",
    "    \n",
    "    # In[122]:\n",
    "    \n",
    "    (df_descend_fisci.ANAIS == df_descend_fisci.ENF_IND_NAI_DATE.str[0:4].astype('float')).value_counts()\n",
    "    \n",
    "    \n",
    "    # In[123]:\n",
    "    \n",
    "    df_descend_fisci.loc[\n",
    "        (df_descend_fisci.ANAIS == df_descend_fisci.ENF_IND_NAI_DATE.str[0:4].astype('float')), 'Birth_date_matched'\n",
    "    ] = True\n",
    "    \n",
    "    \n",
    "    # In[124]:\n",
    "    \n",
    "    df_descend_fisci.shape\n",
    "    \n",
    "    \n",
    "    # In[125]:\n",
    "    \n",
    "    df_descend_fisci[df_descend_fisci.Birth_date_matched][selected_columns].groupby('ID_FISC_LOG_DIFF').count()['ANAIS'].value_counts(normalize = True)\n",
    "    \n",
    "    \n",
    "    # In[126]:\n",
    "    \n",
    "    #(df_fisci.groupby('ID_FISC_LOG_DIFF').count()['ANAIS'] -2).value_counts(normalize = True)\n",
    "    \n",
    "    \n",
    "    # Je compte et sélectionne (via l'index ID_FISC), les obseervations ou l'individu a l'année de naissance qui correspond.\n",
    "    \n",
    "    # In[127]:\n",
    "    \n",
    "    nb_matched_child = pd.DataFrame(\n",
    "        df_descend_fisci[df_descend_fisci.Birth_date_matched][selected_columns].groupby('ID_FISC_LOG_DIFF').count()['ANAIS']\n",
    "        )\n",
    "    \n",
    "    \n",
    "    # In[128]:\n",
    "    \n",
    "    nb_matched_child.shape\n",
    "    \n",
    "    \n",
    "    # In[129]:\n",
    "    \n",
    "    nb_child =  pd.DataFrame(\n",
    "        df_fisci.groupby('ID_FISC_LOG_DIFF').count()['ANAIS']-2\n",
    "        )\n",
    "    \n",
    "    \n",
    "    # In[130]:\n",
    "    \n",
    "    compare_child_in_household = pd.merge(nb_matched_child, nb_child, left_index=True, right_index=True)\n",
    "    \n",
    "    \n",
    "    # In[131]:\n",
    "    \n",
    "    compare_child_in_household.shape\n",
    "    \n",
    "    \n",
    "    # Compare le nombre d'enfant dans le foyer.\n",
    "    \n",
    "    # In[132]:\n",
    "    \n",
    "    (compare_child_in_household['ANAIS_x'] == compare_child_in_household['ANAIS_y']).value_counts()\n",
    "    \n",
    "    \n",
    "    # 59640 foyers ont le même nombre d'enfants que le nombre d'évenement naissance d'état civil avec la même année de naissance pour chaque enfant.\n",
    "    \n",
    "    # In[133]:\n",
    "    \n",
    "    keep_same_child_number_fisc_log_diff = compare_child_in_household[\n",
    "        (compare_child_in_household['ANAIS_x'] == compare_child_in_household['ANAIS_y'])\n",
    "        ].index\n",
    "    \n",
    "    \n",
    "    # In[134]:\n",
    "    \n",
    "    df_descend_fisci_same_child_number = df_descend_fisci[\n",
    "        df_descend_fisci.ID_FISC_LOG_DIFF.isin(keep_same_child_number_fisc_log_diff)\n",
    "        ]\n",
    "    \n",
    "    \n",
    "    # In[135]:\n",
    "    \n",
    "    df_descend_fisci_same_child_number.ID_FISC_LOG_DIFF\n",
    "    \n",
    "    \n",
    "    # In[136]:\n",
    "    \n",
    "    df_descend_fisci_same_child_number.groupby('ID_FISC_LOG_DIFF').count().ANAIS.astype('bool').value_counts()\n",
    "    \n",
    "    \n",
    "    # In[137]:\n",
    "    \n",
    "    selected_columns\n",
    "    \n",
    "    \n",
    "    # In[ ]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Mal fait les merge du coup on se retrouve avec des individus dupliqués, on les droppe un peu à la bourrin.\n",
    "    \n",
    "    # In[138]:\n",
    "    \n",
    "    \n",
    "    df_descend_fisci_same_child_number = df_descend_fisci_same_child_number.drop_duplicates([\"Id_fisc\" ])\n",
    "    \n",
    "    \n",
    "    # In[139]:\n",
    "    \n",
    "    \n",
    "    df_descend_fisci_same_child_number[df_descend_fisci_same_child_number.Birth_date_matched][selected_columns].ID_FISC_LOG_DIFF.nunique()\n",
    "    \n",
    "    \n",
    "    # In[140]:\n",
    "    \n",
    "    df_descend_fisci_same_child_number.shape\n",
    "    \n",
    "    \n",
    "    # In[ ]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # #### Vérifie qu'on a bien le même nombre d'individus dans chaque logement fiscal \n",
    "    \n",
    "    # In[141]:\n",
    "    \n",
    "    check_id_diff = df_descend_fisci_same_child_number.ID_FISC_LOG_DIFF\n",
    "    \n",
    "    \n",
    "    # In[142]:\n",
    "    \n",
    "    check_fisci_number = df_fisci[df_fisci.ID_FISC_LOG_DIFF.isin(df_descend_fisci_same_child_number.ID_FISC_LOG_DIFF)\n",
    "                   ].groupby('ID_FISC_LOG_DIFF').count().sort_index().ANAIS\n",
    "    \n",
    "    \n",
    "    # In[143]:\n",
    "    \n",
    "    check_descend_fisci_same_child_number = df_descend_fisci_same_child_number.groupby('ID_FISC_LOG_DIFF').count().sort_index().ANAIS\n",
    "    \n",
    "    \n",
    "    # In[144]:\n",
    "    \n",
    "    (check_fisci_number== check_descend_fisci_same_child_number).value_counts()\n",
    "    \n",
    "    \n",
    "    # YES !!! Meme nombre d'individus dans tout les menages selectionnes.\n",
    "    \n",
    "    # In[145]:\n",
    "    \n",
    "    df_descend_fisci_same_child_number.sort('ID_FISC_LOG_DIFF')[selected_columns].head()\n",
    "    \n",
    "    \n",
    "    # In[146]:\n",
    "    \n",
    "    df_descend_fisci_same_child_number['PERE_IND_NAI_DATE'] = pd.to_datetime(\n",
    "        df_descend_fisci_same_child_number['PERE_IND_NAI_DATE'], infer_datetime_format=True, coerce=True\n",
    "        )\n",
    "    df_descend_fisci_same_child_number['MERE_IND_NAI_DATE'] = pd.to_datetime(\n",
    "        df_descend_fisci_same_child_number['MERE_IND_NAI_DATE'], infer_datetime_format=True, coerce=True\n",
    "        )\n",
    "    \n",
    "    \n",
    "    # In[147]:\n",
    "    \n",
    "    pas_meme_date_pere = ~(df_descend_fisci_same_child_number.Date_Naissance_Pere_fisci_y == \n",
    "                          df_descend_fisci_same_child_number.PERE_IND_NAI_DATE)\n",
    "    pas_meme_date_mere = ~(df_descend_fisci_same_child_number.Date_Naissance_Mere_fisci_y == df_descend_fisci_same_child_number.MERE_IND_NAI_DATE)\n",
    "    \n",
    "    \n",
    "    # In[148]:\n",
    "    \n",
    "    df_descend_fisci_same_child_number.TYPE_FISC != '1'\n",
    "    \n",
    "    \n",
    "    # In[149]:\n",
    "    \n",
    "    pas_meme_date_pere = (~(df_descend_fisci_same_child_number.Date_Naissance_Pere_fisci_y == \n",
    "                          df_descend_fisci_same_child_number.PERE_IND_NAI_DATE)&\n",
    "                          (df_descend_fisci_same_child_number.TYPE_FISC != '1'))\n",
    "    pas_meme_date_mere = (~(df_descend_fisci_same_child_number.Date_Naissance_Mere_fisci_y == \n",
    "                           df_descend_fisci_same_child_number.MERE_IND_NAI_DATE)&\n",
    "                          (df_descend_fisci_same_child_number.TYPE_FISC != '1'))\n",
    "    \n",
    "    \n",
    "    # In[150]:\n",
    "    \n",
    "    print pas_meme_date_pere.value_counts()\n",
    "    print pas_meme_date_pere.value_counts(normalize=True)\n",
    "    \n",
    "    \n",
    "    # In[151]:\n",
    "    \n",
    "    print pas_meme_date_mere.value_counts()\n",
    "    print pas_meme_date_mere.value_counts(normalize=True)\n",
    "    \n",
    "    \n",
    "    # In[152]:\n",
    "    \n",
    "    df_descend_fisci_same_child_number['Pas_meme_date_Pere'] = pas_meme_date_pere\n",
    "    df_descend_fisci_same_child_number['Pas_meme_date_Mere'] = pas_meme_date_mere\n",
    "    \n",
    "    \n",
    "    # In[153]:\n",
    "    \n",
    "    (df_descend_fisci_same_child_number.groupby('ID_FISC_LOG_DIFF').sum()['Pas_meme_date_Pere'].astype('bool')).value_counts()\n",
    "    \n",
    "    \n",
    "    # In[154]:\n",
    "    \n",
    "    (\n",
    "        (df_descend_fisci_same_child_number.groupby('ID_FISC_LOG_DIFF').sum()['Pas_meme_date_Pere'].astype('bool'))|\n",
    "        (df_descend_fisci_same_child_number.groupby('ID_FISC_LOG_DIFF').sum()['Pas_meme_date_Mere'].astype('bool'))\n",
    "      ).value_counts()\n",
    "    \n",
    "    \n",
    "    # In[155]:\n",
    "    \n",
    "    (\n",
    "        (df_descend_fisci_same_child_number.groupby('ID_FISC_LOG_DIFF').sum()['Pas_meme_date_Pere'].astype('bool'))|\n",
    "        (df_descend_fisci_same_child_number.groupby('ID_FISC_LOG_DIFF').sum()['Pas_meme_date_Mere'].astype('bool'))\n",
    "      ).value_counts(normalize = True)\n",
    "    \n",
    "    \n",
    "    # Parmis les foyers sans union civile avec au moins un enfant mais dont aucun n'est en garde alternée, dont toutes les naissances de chaque enfant est renseignée dans l'état civil, on a  10% des foyers ont la mère ou le père qui n'est pas biologique.\n",
    "    \n",
    "    # In[156]:\n",
    "    \n",
    "    not_biologic_drop = (\n",
    "        (df_descend_fisci_same_child_number.groupby('ID_FISC_LOG_DIFF').sum()['Pas_meme_date_Pere'].astype('bool'))|\n",
    "        (df_descend_fisci_same_child_number.groupby('ID_FISC_LOG_DIFF').sum()['Pas_meme_date_Mere'].astype('bool'))\n",
    "      )\n",
    "    \n",
    "    \n",
    "    # In[157]:\n",
    "    \n",
    "    not_biologic_drop_id = not_biologic_drop[not_biologic_drop==True].index\n",
    "    \n",
    "    \n",
    "    # In[158]:\n",
    "    \n",
    "    df_fisci_biologic = df_descend_fisci_same_child_number[~(df_descend_fisci_same_child_number.ID_FISC_LOG_DIFF.isin(not_biologic_drop_id))]\n",
    "    \n",
    "    \n",
    "    # In[159]:\n",
    "    \n",
    "    df_descend_fisci_same_child_number.shape\n",
    "    \n",
    "    \n",
    "    # In[160]:\n",
    "    \n",
    "    df_fisci_biologic.shape\n",
    "    \n",
    "    \n",
    "    # In[161]:\n",
    "    \n",
    "    df_fisci_biologic.to_hdf('./Data/hdf/edp_concubin.h5', \n",
    "                             'Biologic_concubin_with_child_under_majority_rev_{}'.format(income_year))\n",
    "    \n",
    "    # In[ ]:\n",
    "    \n",
    "    import pickle\n",
    "    path = (u\"./Programme/pickle/optimize/Biologic/\")\n",
    "    \n",
    "    pickle.dump(df_fisci_biologic.ID_FISC_LOG_DIFF.values, \n",
    "            open(path+\"marriage_en_2013_2014.p\", 'wb'))\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "#    for year in [2010]:\n",
    "#        create_data_year(income_year = year)\n",
    "    for year in range(2010,2015):\n",
    "        create_data_year(income_year = year)\n",
    "        print'year :{}'.format(year) *50\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
